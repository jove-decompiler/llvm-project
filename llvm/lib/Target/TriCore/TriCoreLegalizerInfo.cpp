//===-- TriCoreLegalizerInfo.cpp --------------------------------*- C++ -*-===//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//===----------------------------------------------------------------------===//
/// \file
/// This file implements the targeting of the Machinelegalizer class for
/// TriCore.
/// \todo This should be generated by TableGen.
//===----------------------------------------------------------------------===//

#include "TriCoreLegalizerInfo.h"
#include "TriCoreSubtarget.h"
#include "llvm/CodeGen/TargetOpcodes.h"

using namespace llvm;

TriCoreLegalizerInfo::TriCoreLegalizerInfo(const TriCoreSubtarget &ST) {
  using namespace TargetOpcode;
  const LLT p0 = LLT::pointer(0, 32);
  const LLT s1 = LLT::scalar(1);
  const LLT s8 = LLT::scalar(8);
  const LLT s16 = LLT::scalar(16);
  const LLT s32 = LLT::scalar(32);
  const LLT s64 = LLT::scalar(64);

  // at least one G_IMPLICIT_DEF must be legal. we allow all types
  getActionDefinitionsBuilder(G_IMPLICIT_DEF)
      .legalFor({p0, s1, s8, s16, s32, s64})
      .clampScalar(0, s1, s64)
      .widenScalarToNextPow2(0, 32);

  // G_PHI should be legal for all consumed types to avoid unnecessary
  // truncations and extensions
  getActionDefinitionsBuilder(G_PHI)
      .legalFor({p0, s8, s16, s32, s64})
      .clampScalar(0, s8, s64)
      .widenScalarToNextPow2(0);

  // Pointers

  // G_GLOBAL_VALUE and G_FRAME_INDEX are only valid for pointers
  getActionDefinitionsBuilder({G_FRAME_INDEX, G_GLOBAL_VALUE}).legalFor({p0});

  // G_INTTOPTR requires the scalar to have the same number of bits as the
  // pointer. It is not legal to narrow/widen the scalar as the extended/lost
  // bits change the address.
  getActionDefinitionsBuilder(G_INTTOPTR).legalFor({{p0, s32}});

  // G_PTRTOINT goes from a 32-bit pointer to a 32-bit scalar.
  getActionDefinitionsBuilder(G_PTRTOINT)
      .legalFor({{s32, p0}})
      .clampScalar(0, s32, s32);

  // Constants

  // G_CONSTANT is only legal for types that match our register size
  getActionDefinitionsBuilder(G_CONSTANT)
      .legalFor({p0, s32, s64})
      .clampScalar(0, s32, s64)
      .widenScalarToNextPow2(0);

  // Binary Ops

  // Simple binary operators are only legal for s32 types.
  getActionDefinitionsBuilder(
      {G_ADD, G_SUB, G_AND, G_OR, G_XOR, G_MUL, G_UMULH})
      .legalFor({s32})
      .clampScalar(0, s32, s32);

  // G_SDIV is only legal for 32 bit types and has to be lowered for 64 bit type
  getActionDefinitionsBuilder(G_SDIV)
      .legalFor({s32})
      .minScalar(0, s32)
      .libcallFor({s64});

  // G_PTR_ADD must take a p0 and s32 operand
  getActionDefinitionsBuilder(G_PTR_ADD)
      .legalFor({{p0, s32}})
      .clampScalar(1, s32, s32);

  // Overflow Ops

  // All variants of add/sub /w carry must produce an s32 result and an s1 carry
  getActionDefinitionsBuilder({G_UADDE, G_USUBE, G_UADDO, G_USUBO})
      .legalFor({{s32, s1}});

  // Shifts

  // G_SHL, G_LSHR and G_ASHR always produce the same type as their src type
  // (type idx 0, 32-bit). Additionally, only 32-bit shift amounts (type idx 1)
  // are allowed.
  getActionDefinitionsBuilder({G_SHL, G_LSHR, G_ASHR})
      .legalFor({{s32, s32}})
      .clampScalar(1, s32, s32)
      .clampScalar(0, s32, s32);

  // Comparisons & Select

  // G_ICMP is only legal for scalar 32-bit and pointer types. Result is s32.
  getActionDefinitionsBuilder(G_ICMP)
      .legalFor({{s32, s32}, {s32, p0}})
      .clampScalar(1, s32, s32)
      .clampScalar(0, s32, s32);

  // G_SELECT is only valid for 32-bit and pointer types. Condition is s1.
  getActionDefinitionsBuilder(G_SELECT)
      .legalFor({{s32, s1}, {p0, s1}})
      .clampScalar(0, s32, s32);

  // Extensions

  // G_{ANY,S,Z}EXT must be legal for all input types produced by at least one
  // legal instruction and all larger output types consumed by at least one
  // legal instruction
  getActionDefinitionsBuilder({G_ANYEXT, G_SEXT, G_ZEXT})
      .legalForCartesianProduct({s8, s16, s32, s64}, {s1, s8, s16, s32});

  // G_TRUNC is always legal as we can handle code-gen implications on the
  // extension side. Also this helps us to avoid certain code-duplications
  getActionDefinitionsBuilder(G_TRUNC).alwaysLegal();

  // Load & Store

  // G_LOAD is legal for 32 and 64-bit scalar and pointer types.
  // Memory size must be a power of 2.
  getActionDefinitionsBuilder(G_LOAD)
      .legalForTypesWithMemDesc({
          // Minimum alignment for all cases can be 8 bits (1 byte)
          {s32, p0, 8, 8},
          {s32, p0, 16, 8},
          {s32, p0, 32, 8},
          {s64, p0, 64, 8},
          {p0, p0, 32, 8},
      })
      .lowerIfMemSizeNotPow2()
      .clampScalar(0, s32, s64)
      // Lower any extending loads left into G_ANYEXT and G_LOAD
      .lowerIf([=](const LegalityQuery &Query) {
        return Query.Types[0].getSizeInBits() != Query.MMODescrs[0].SizeInBits;
      })
      .widenScalarToNextPow2(0);

  // G_STORE is legal for pointers and scalars if the store size is equal to the
  // scalar type size. Different to G_LOAD, we require explicit s8 and s16
  // value types, because this allows to match every possible store with
  // TableGen instead of having to fall back to C++ for truncating stores.
  getActionDefinitionsBuilder(G_STORE)
      .legalForTypesWithMemDesc({
          // Minimum alignment for all cases can be 8 bits (1 byte)
          {s8, p0, 8, 8},
          {s16, p0, 16, 8},
          {s32, p0, 32, 8},
          {s64, p0, 64, 8},
          {p0, p0, 32, 8},
      })
      .clampScalar(0, s8, s64)
      .lowerIfMemSizeNotPow2()
      // Lower truncating stores into G_TRUNC and G_STORE
      .narrowScalarIf(
          [=](const LegalityQuery &Query) {
            return Query.Types[0].getSizeInBits() >
                   Query.MMODescrs[0].SizeInBits;
          },
          [=](const LegalityQuery &Query) {
            // Use the memory size as size for the new type
            const unsigned MemSize = Query.MMODescrs[0].SizeInBits;
            return std::make_pair(0, LLT::scalar(MemSize));
          })
      .widenScalarToNextPow2(0);

  // G_SEXTLOAD and G_ZEXTLOAD are legal for a 32-bit result type
  getActionDefinitionsBuilder({G_SEXTLOAD, G_ZEXTLOAD})
      .legalForTypesWithMemDesc({
          {s32, p0, 8, 8},
          {s32, p0, 16, 16},
          {s32, p0, 32, 32},
      })
      .clampScalar(0, s32, s32)
      .lowerIfMemSizeNotPow2()
      // Lower anything left over to G_*EXT and G_LOAD
      .lower();

  // G_MERGE_VALUES and G_UNMERGE_VALUES should require the smaller type to
  // be s32 and the bigger type to be 64 bits
  for (unsigned OpCode : {G_MERGE_VALUES, G_UNMERGE_VALUES}) {
    unsigned BigTyIdx = OpCode == G_MERGE_VALUES ? 0 : 1;
    unsigned SmallTyIdx = OpCode == G_MERGE_VALUES ? 1 : 0;

    getActionDefinitionsBuilder(OpCode)
        .legalIf([=](const LegalityQuery &Query) {
          const LLT &BigTy = Query.Types[BigTyIdx];
          const LLT &SmallTy = Query.Types[SmallTyIdx];

          return SmallTy == s32 && BigTy == s64;
        })
        .clampScalar(SmallTyIdx, s32, s32)
        .clampScalar(BigTyIdx, s64, s64);
  }

  // Branches

  // G_BRCOND is valid for s1 and s32 scalars.
  getActionDefinitionsBuilder(G_BRCOND).legalFor({s1, s32});

  // G_BRINDIRECT is valid for p0 types.
  getActionDefinitionsBuilder(G_BRINDIRECT).legalFor({p0});

  computeTables();
  verify(*ST.getInstrInfo());
}
