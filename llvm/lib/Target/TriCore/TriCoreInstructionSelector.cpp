//===-- TriCoreInstructionSelector.cpp ---------------------------*- C++ -*-==//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//===----------------------------------------------------------------------===//
/// \file
/// This file implements the targeting of the InstructionSelector class for
/// TriCore.
/// \todo This should be generated by TableGen.
//===----------------------------------------------------------------------===//

#include "TriCoreMachineFunctionInfo.h"
#include "TriCoreRegisterBankInfo.h"
#include "TriCoreSubtarget.h"
#include "TriCoreTargetMachine.h"
#include "Utils/TriCoreBaseInfo.h"
#include "llvm/CodeGen/GlobalISel/InstructionSelector.h"
#include "llvm/CodeGen/GlobalISel/InstructionSelectorImpl.h"
#include "llvm/Support/MathExtras.h"

#define DEBUG_TYPE "tricore-isel"

using namespace llvm;

#define GET_GLOBALISEL_PREDICATE_BITSET
#include "TriCoreGenGlobalISel.inc"
#undef GET_GLOBALISEL_PREDICATE_BITSET

namespace {

class TriCoreInstructionSelector : public InstructionSelector {
public:
  TriCoreInstructionSelector(const TriCoreTargetMachine &TM,
                             const TriCoreSubtarget &STI,
                             const TriCoreRegisterBankInfo &RBI);

  bool select(MachineInstr &I) override;
  static const char *getName() { return DEBUG_TYPE; }

private:
  bool selectImpl(MachineInstr &I, CodeGenCoverage &CoverageInfo) const;

  const TriCoreInstrInfo &TII;
  const TriCoreRegisterInfo &TRI;
  const TriCoreRegisterBankInfo &RBI;

  // Global ISel renderer functions for TableGen //
  void renderNegImm(MachineInstrBuilder &MIB, const MachineInstr &MI,
                    int) const;

#define GET_GLOBALISEL_PREDICATES_DECL
#include "TriCoreGenGlobalISel.inc"
#undef GET_GLOBALISEL_PREDICATES_DECL

#define GET_GLOBALISEL_TEMPORARIES_DECL
#include "TriCoreGenGlobalISel.inc"
#undef GET_GLOBALISEL_TEMPORARIES_DECL

  void emit32BitSext(MachineRegisterInfo &MRI, Register DstReg, Register SrcReg,
                     unsigned SrcSize, MachineIRBuilder &MIRBuilder) const;
  void emit32BitZext(MachineRegisterInfo &MRI, Register DstReg, Register SrcReg,
                     unsigned SrcSize, MachineIRBuilder &MIRBuilder) const;

  void emit32BitMerge(ArrayRef<Register> SrcRegs, Register DstReg,
                      MachineIRBuilder &MIRBuilder,
                      MachineRegisterInfo &MRI) const;
  void emit32BitUnmerge(Register SrcReg, ArrayRef<Register> DstRegs,
                        MachineIRBuilder &MIRBuilder,
                        const MachineRegisterInfo &MRI) const;

  bool selectAddSubE(MachineInstr &I, MachineRegisterInfo &MRI) const;
  bool selectAddSubO(MachineInstr &I, MachineRegisterInfo &MRI) const;
  bool selectBrCond(MachineInstr &I, const MachineRegisterInfo &MRI) const;
  bool selectBrIndirect(MachineInstr &I, const MachineRegisterInfo &MRI) const;
  bool selectBrJumpTable(MachineInstr &I, MachineRegisterInfo &MRI,
                         const MachineFunction &MF) const;
  bool selectConstant(MachineInstr &I, MachineRegisterInfo &MRI) const;
  bool selectCmpAndJump(MachineInstr &I, const MachineRegisterInfo &MRI,
                        MachineIRBuilder &MIRBuilder) const;
  bool selectImplicitDef(MachineInstr &I, MachineRegisterInfo &MRI) const;
  bool selectCopy(MachineInstr &I, MachineRegisterInfo &MRI) const;
  bool selectExt(MachineInstr &I, MachineRegisterInfo &MRI) const;
  bool selectExtAny(MachineInstr &I, MachineRegisterInfo &MRI, unsigned DstSize,
                    unsigned SrcSize) const;
  bool selectExtSign(MachineInstr &I, MachineRegisterInfo &MRI,
                     unsigned DstSize, unsigned SrcSize) const;
  bool selectExtZero(MachineInstr &I, MachineRegisterInfo &MRI,
                     unsigned DstSize, unsigned SrcSize) const;
  bool selectFltRounds(MachineInstr &I, MachineRegisterInfo &MRI) const;
  bool selectFPExt(MachineInstr &I, const MachineRegisterInfo &MRI) const;
  bool selectFPTrunc(MachineInstr &I, const MachineRegisterInfo &MRI) const;
  bool selectFrameIndex(MachineInstr &I, const MachineRegisterInfo &MRI) const;
  bool selectFreeze(MachineInstr &I, MachineRegisterInfo &MRI) const;
  bool selectGlobalValue(MachineInstr &I, MachineRegisterInfo &MRI) const;
  bool selectFCmp(MachineInstr &I, MachineRegisterInfo &MRI) const;
  bool selectICmp(MachineInstr &I, const MachineRegisterInfo &MRI) const;
  bool selectIntrinsicWithSideEffects(MachineInstr &I,
                                      MachineRegisterInfo &MRI) const;
  bool selectMerge(MachineInstr &I, MachineRegisterInfo &MRI) const;
  bool selectLoadStore(MachineInstr &I, const MachineRegisterInfo &MRI) const;
  bool selectPtrAdd(MachineInstr &I, const MachineRegisterInfo &MRI) const;
  bool selectSelect(MachineInstr &I, const MachineRegisterInfo &MRI) const;
  bool selectTrunc(MachineInstr &I, MachineRegisterInfo &MRI) const;
  bool selectUnmerge(MachineInstr &I, MachineRegisterInfo &MRI) const;
  bool selectVaStart(MachineInstr &I, MachineFunction &MF,
                     MachineRegisterInfo &MRI) const;

  // Optimization methods.
  bool tryFoldIntegerCompare(MachineInstr &I) const;
};

} // end anonymous namespace

#define GET_GLOBALISEL_IMPL
#include "TriCoreGenGlobalISel.inc"
#undef GET_GLOBALISEL_IMPL

TriCoreInstructionSelector::TriCoreInstructionSelector(
    const TriCoreTargetMachine &TM, const TriCoreSubtarget &STI,
    const TriCoreRegisterBankInfo &RBI)
    : InstructionSelector(), TII(*STI.getInstrInfo()),
      TRI(*STI.getRegisterInfo()), RBI(RBI),

#define GET_GLOBALISEL_PREDICATES_INIT
#include "TriCoreGenGlobalISel.inc"
#undef GET_GLOBALISEL_PREDICATES_INIT
#define GET_GLOBALISEL_TEMPORARIES_INIT
#include "TriCoreGenGlobalISel.inc"
#undef GET_GLOBALISEL_TEMPORARIES_INIT
{
}

static bool checkType(const LLT &ExpectedTy, const LLT &ActualTy,
                      const std::string &OpCode) {
  if (ActualTy != ExpectedTy) {
    LLVM_DEBUG(dbgs() << OpCode << " has type " << ActualTy << ", expected "
                      << ExpectedTy << "\n");
    return false;
  }

  return true;
}

/// Helper function to find an intrinsic ID on a MachineInstr. Returns the
/// ID if it exists, and 0 otherwise.
static unsigned findIntrinsicID(MachineInstr &I) {
  auto IntrinOp = find_if(I.operands(), [&](const MachineOperand &Op) {
    return Op.isIntrinsicID();
  });
  if (IntrinOp == I.operands_end())
    return 0;
  return IntrinOp->getIntrinsicID();
}

// An OpcTable must have 10 entries (number of comparison predicates) each for
// scalars and pointers
static const unsigned NumPredicates = 10;
static const unsigned OpcTableSize = NumPredicates * 2;

// An OpcTable is a table which has a target op-code entry for each predicate,
// once for scalars and once for pointers. If for a certain predicate-type
// combination a target op-code is not available or if the operation itself is
// invalid (e.g. signed pointer comparisons) it must hold a 0. The order of the
// table is as follows:
//
// ne, eq, sge, uge, slt, ult, sgt, ugt, sle, ule
//
// repeated twice: first for scalars, then for pointers
typedef unsigned OpcTableTy[OpcTableSize];

static unsigned getOpCodeForPredicate(CmpInst::Predicate Predicate,
                                      const RegisterBank &RB,
                                      bool &SwapOperands,
                                      const OpcTableTy &OpcTable) {
  unsigned PredicateIdx;
  switch (Predicate) {
  default:
    llvm_unreachable("Unknown compare predicate!");
  // TriCore does not have GT and LE. Use LT and GE with flipped operands.
  case CmpInst::ICMP_NE:
    PredicateIdx = 0;
    break;
  case CmpInst::ICMP_EQ:
    PredicateIdx = 1;
    break;
  case CmpInst::ICMP_SLE:
    SwapOperands = true;
    LLVM_FALLTHROUGH;
  case CmpInst::ICMP_SGE:
    PredicateIdx = 2;
    break;
  case CmpInst::ICMP_ULE:
    SwapOperands = true;
    LLVM_FALLTHROUGH;
  case CmpInst::ICMP_UGE:
    PredicateIdx = 3;
    break;
  case CmpInst::ICMP_SGT:
    SwapOperands = true;
    LLVM_FALLTHROUGH;
  case CmpInst::ICMP_SLT:
    PredicateIdx = 4;
    break;
  case CmpInst::ICMP_UGT:
    SwapOperands = true;
    LLVM_FALLTHROUGH;
  case CmpInst::ICMP_ULT:
    PredicateIdx = 5;
    break;
  }

  unsigned Offset = RB.getID() == TriCore::AddrRegBankID ? 1 : 0;

  const unsigned OpcTableIdx = PredicateIdx + Offset * NumPredicates;
  assert(OpcTableIdx < OpcTableSize && "OpcTableIdx out of bounds");

  return OpcTable[OpcTableIdx];
}

static unsigned getCmpOpCodeForPredicate(CmpInst::Predicate Predicate,
                                         const RegisterBank &RB,
                                         bool &SwapOperands) {
  static const OpcTableTy OpcTable = {
      // Scalar + pointer compares
      TriCore::NE_ddd,
      TriCore::EQ_ddd,
      TriCore::GE_ddd,
      TriCore::GEU_ddd,
      TriCore::LT_ddd,
      TriCore::LTU_ddd,
      /* no GT instruction */ 0,
      /* no GT.U instruction */ 0,
      /* no LE instruction */ 0,
      /* no LE.U instruction */ 0,
      TriCore::NEA_daa,
      TriCore::EQA_daa,
      /* signed pointer compare is invalid */ 0,
      TriCore::GEA_daa,
      /* signed pointer compare is invalid */ 0,
      TriCore::LTA_daa,
      /* signed pointer compare is invalid */ 0,
      /* no GT.A instruction */ 0,
      /* signed pointer compare is invalid */ 0,
      /* no LE.A instruction */ 0,
  };

  return getOpCodeForPredicate(Predicate, RB, SwapOperands, OpcTable);
}

static unsigned getCompareWithImmediateOpcode(unsigned CmpRegReg, int64_t Imm) {

  switch(CmpRegReg) {
  default:
    return 0;
  case TriCore::JNE_ddc:
    return isInt<4>(Imm) ? TriCore::JNE_dcc : 0;
  case TriCore::JEQ_ddc:
    return isInt<4>(Imm) ? TriCore::JEQ_dcc : 0;
  case TriCore::JGE_ddc:
    return isInt<4>(Imm) ? TriCore::JGE_dcc : 0;
  case TriCore::JGEU_ddc:
    return isUInt<4>(Imm) ? TriCore::JGEU_dcc : 0;
  case TriCore::JLT_ddc:
    return isInt<4>(Imm) ? TriCore::JLT_dcc : 0;
  case TriCore::JLTU_ddc:
    return isUInt<4>(Imm) ? TriCore::JLTU_dcc : 0;
  }
}

bool TriCoreInstructionSelector::tryFoldIntegerCompare(MachineInstr &I) const {
  MachineIRBuilder MIRBuilder(I);
  MachineRegisterInfo &MRI = *MIRBuilder.getMRI();
  const TargetRegisterInfo &TRI = *MRI.getTargetRegisterInfo();

  // If there is a constant operand, it should always be the RHS operand
  auto VRegAndVal =
      getConstantVRegValWithLookThrough(I.getOperand(3).getReg(), MRI);
  if (!VRegAndVal)
    return false;

  CmpInst::Predicate P = (CmpInst::Predicate)I.getOperand(1).getPredicate();
  int64_t Imm = VRegAndVal->Value;

  bool IsImm9 = isInt<9>(Imm);
  bool IsUImm9 = isUInt<9>(Imm);

  const Register &SrcReg = I.getOperand(2).getReg();
  const RegisterBank *RB = RBI.getRegBank(SrcReg, MRI, TRI);

  unsigned Opcode = 0;
  bool AddImm = true;
  if (RB->getID() == TriCore::AddrRegBankID) {
    // On the address register bank, we only have immediate compares against
    // zero
    if (Imm != 0)
      return false;

    switch (P) {
    default:
      return false;
    case CmpInst::ICMP_EQ:
    case CmpInst::ICMP_NE:
      Opcode = (P == CmpInst::ICMP_EQ) ? TriCore::EQZA_da : TriCore::NEZA_da;
      AddImm = false;
      break;
    }
  } else {
    switch (P) {
    default:
      return false;
    case CmpInst::ICMP_EQ:
    case CmpInst::ICMP_NE:
    case CmpInst::ICMP_SGE:
    case CmpInst::ICMP_SLT:
      if (!IsImm9)
        return false;
      break;
    case CmpInst::ICMP_UGE:
    case CmpInst::ICMP_ULT:
      if (!IsUImm9)
        return false;
      break;
    case CmpInst::ICMP_UGT:
    case CmpInst::ICMP_ULE:
      if ((static_cast<uint32_t>(Imm) == UINT32_MAX) || !isUInt<9>(Imm + 1))
        return false;
      Imm++;
      break;
    case CmpInst::ICMP_SGT:
    case CmpInst::ICMP_SLE:
      if (!isInt<9>(Imm + 1))
        return false;
      Imm++;
      break;
    }

#define PRED_TO_OP_CASE(pred, op)                                              \
  case pred:                                                                   \
    Opcode = op;                                                               \
    break

    switch (P) {
    default:
      return false;
      PRED_TO_OP_CASE(CmpInst::ICMP_EQ, TriCore::EQ_ddc);
      PRED_TO_OP_CASE(CmpInst::ICMP_NE, TriCore::NE_ddc);
      PRED_TO_OP_CASE(CmpInst::ICMP_UGT, TriCore::GEU_ddc);
      PRED_TO_OP_CASE(CmpInst::ICMP_UGE, TriCore::GEU_ddc);
      PRED_TO_OP_CASE(CmpInst::ICMP_ULE, TriCore::LTU_ddc);
      PRED_TO_OP_CASE(CmpInst::ICMP_ULT, TriCore::LTU_ddc);
      PRED_TO_OP_CASE(CmpInst::ICMP_SGT, TriCore::GE_ddc);
      PRED_TO_OP_CASE(CmpInst::ICMP_SGE, TriCore::GE_ddc);
      PRED_TO_OP_CASE(CmpInst::ICMP_SLE, TriCore::LT_ddc);
      PRED_TO_OP_CASE(CmpInst::ICMP_SLT, TriCore::LT_ddc);
    }

#undef PRED_TO_OP_CASE
  }

  assert(Opcode != 0 && "No opcode found!");

  auto CmpInst = MIRBuilder.buildInstr(Opcode)
                     .addDef(I.getOperand(0).getReg())
                     .addUse(SrcReg);
  if (AddImm)
    CmpInst.addImm(Imm);

  constrainSelectedInstRegOperands(*CmpInst, TII, TRI, RBI);
  return true;
}

static unsigned getBranchOpCodeForPredicate(CmpInst::Predicate Predicate,
                                            const RegisterBank &RB,
                                            bool &SwapOperands) {
  static const OpcTableTy OpcTable = {
      // Scalar + pointer compare-and-jumps
      TriCore::JNE_ddc,
      TriCore::JEQ_ddc,
      TriCore::JGE_ddc,
      TriCore::JGEU_ddc,
      TriCore::JLT_ddc,
      TriCore::JLTU_ddc,
      /* no JGT instruction */ 0,
      /* no JGT.U instruction */ 0,
      /* no JLE instruction */ 0,
      /* no JLE.U instruction */ 0,
      TriCore::JNEA_aac,
      TriCore::JEQA_aac,
      /* signed pointer compare is invalid */ 0,
      /* no JGE.A instruction */ 0,
      /* signed pointer compare is invalid */ 0,
      /* no JLT.A instruction */ 0,
      /* signed pointer compare is invalid */ 0,
      /* no JGT.A instruction */ 0,
      /* signed pointer compare is invalid */ 0,
      /* no JLE.A instruction */ 0,
  };

  return getOpCodeForPredicate(Predicate, RB, SwapOperands, OpcTable);
}

struct FCmpConstants {
  // The opcode used to extract the result bits from the comparison result
  unsigned SelectResultOpcode;
  // The bit-offset from the first bit to extract
  unsigned FirstBitOffset;
  // The bit-offset from the second bit to extract
  unsigned SecondBitOffset;
};

static FCmpConstants getFCmpConstants(CmpInst::Predicate Pred) {
  switch (Pred) {
  default:
    llvm_unreachable("FCMP predicate can be handled by TableGen.");
  case CmpInst::FCMP_ONE:
    return {TriCore::ORT_ddcdc, 2, 0};
  case CmpInst::FCMP_OLE:
    return {TriCore::ORT_ddcdc, 1, 0};
  case CmpInst::FCMP_OGE:
    return {TriCore::ORT_ddcdc, 2, 1};
  case CmpInst::FCMP_ORD:
    return {TriCore::NORT_ddcdc, 3, 3};
  case CmpInst::FCMP_UEQ:
    return {TriCore::ORT_ddcdc, 3, 1};
  case CmpInst::FCMP_UGT:
    return {TriCore::ORT_ddcdc, 3, 2};
  case CmpInst::FCMP_ULT:
    return {TriCore::ORT_ddcdc, 3, 0};
  }
}

static unsigned getLoadStoreOpCode(const unsigned Opc, const unsigned RegBankID,
                                   const unsigned MemorySizeInBits) {
  const bool IsStore = Opc == TargetOpcode::G_STORE;
  const bool IsZextLoad = Opc == TargetOpcode::G_ZEXTLOAD;

  switch (RegBankID) {
  case TriCore::DataRegBankID:
    switch (MemorySizeInBits) {
    case 8:
      return IsStore ? TriCore::STB_alcd
                     : IsZextLoad ? TriCore::LDBU_dalc : TriCore::LDB_dalc;
    case 16:
      return IsStore ? TriCore::STH_alcd
                     : IsZextLoad ? TriCore::LDHU_dalc : TriCore::LDH_dalc;
    case 32:
      return IsStore ? TriCore::STW_alcd : TriCore::LDW_dalc;
    case 64:
      return IsStore ? TriCore::STD_ace : TriCore::LDD_eac;
    }
  case TriCore::AddrRegBankID:
    switch (MemorySizeInBits) {
    case 32:
      return IsStore ? TriCore::STA_alca : TriCore::LDA_aalc;
    case 64:
      return IsStore ? TriCore::STDA_acp : TriCore::LDDA_pac;
    }
  }

  return Opc;
}

static const TargetRegisterClass *
getRegClassForRegBank(const RegisterBank &RB, const unsigned SizeInBits) {
  unsigned RegBankID = RB.getID();

  // Return the minimum register class for the given RegisterBank and SizeInBits
  if (RegBankID == TriCore::AddrRegBankID) {
    if (SizeInBits <= 32)
      return &TriCore::AddrRegsRegClass;
    if (SizeInBits <= 64)
      return &TriCore::ExtAddrRegsRegClass;
    return nullptr;
  }
  if (RegBankID == TriCore::DataRegBankID) {
    if (SizeInBits <= 32)
      return &TriCore::DataRegsRegClass;
    if (SizeInBits <= 64)
      return &TriCore::ExtDataRegsRegClass;
    return nullptr;
  }
  return nullptr;
}

static const TargetRegisterClass *
getRegClassForTypeOnBank(const LLT Ty, const RegisterBank &RB) {
  if (RB.getID() == TriCore::DataRegBankID) {
    if (Ty.getSizeInBits() <= 32)
      return &TriCore::DataRegsRegClass;
    else if (Ty.getSizeInBits() <= 64)
      return &TriCore::ExtDataRegsRegClass;
    return nullptr;
  }

  if (RB.getID() == TriCore::AddrRegBankID) {
    if (Ty.getSizeInBits() <= 32)
      return &TriCore::AddrRegsRegClass;
    else if (Ty.getSizeInBits() <= 64)
      return &TriCore::ExtAddrRegsRegClass;
    return nullptr;
  }

  return nullptr;
}

static bool isCarryOutProducer(const MachineInstr &I) {
  switch (I.getOpcode()) {
  default:
    return false;
  case TargetOpcode::G_UADDO:
  case TargetOpcode::G_UADDE:
  case TargetOpcode::G_USUBO:
  case TargetOpcode::G_USUBE:
    return true;
  }
}

static bool isCarryOutClobberedBeforeUse(const MachineInstr &MI,
                                         const MachineRegisterInfo &MRI) {
  assert(isCarryOutProducer(MI));

  const Register &CarryOutReg = MI.getOperand(1).getReg();

  assert(MRI.getType(CarryOutReg).getSizeInBits() == 1 &&
         CarryOutReg.isVirtual() &&
         "Expected a virtual carry-out register of 1-bit");

  // To check whether a carry-out is clobbered before use we loop over all uses
  // and then check all dominating instructions in reverse order up to the
  // carry-out definition. If one of these instructions writes $psw_c, it
  // clobbers the carry-out
  const auto RE = MI.getReverseIterator();
  for (auto I = MRI.use_instr_nodbg_begin(CarryOutReg),
            E = MachineRegisterInfo::use_instr_nodbg_end();
       I != E; ++I) {
    const MachineInstr &Use = *I;

    // Iterate from Use to MI, skipping Use itself
    for (auto RI = std::next(Use.getReverseIterator()); RI != RE; ++RI) {
      const MachineInstr &Inst = *RI;

      // Stop if we reach the original instruction
      if (&Inst == &MI)
        break;

      // Instruction selector works bottom up, so this instructions should have
      // been selected already
      assert(!isPreISelGenericOpcode(Inst.getOpcode()) &&
             "Expected already-selected instruction");

      // Check if this instruction clobbers $psw_c
      if (Inst.definesRegister(TriCore::PSW_C, MRI.getTargetRegisterInfo())) {
        LLVM_DEBUG(dbgs() << Inst << " clobbers carry-out register "
                          << CarryOutReg << '\n');
        return true;
      }
    }
  }

  return false;
}

bool TriCoreInstructionSelector::select(MachineInstr &I) {
  assert(I.getParent() && "Instruction should be in a basic block!");
  assert(I.getParent()->getParent() && "Instruction should be in a function!");

  MachineBasicBlock &MBB = *I.getParent();
  MachineFunction &MF = *MBB.getParent();
  MachineRegisterInfo &MRI = MF.getRegInfo();

  const unsigned OpCode = I.getOpcode();

  if (!isPreISelGenericOpcode(OpCode) || I.isPHI()) {
    // We can run into the following problem with COPYs:
    //
    // %0 = G_FOO ...
    // %1 = COPY %0
    // %2 = COPY %1
    // %3 = G_FOO %2, ...
    //
    // This will result in %1 not being constrained to a register class: while
    // %0, %2 and %3 are being constrained through the selection of G_FOO, %1 is
    // not being restrained anywhere.
    // Therefore we need to handle COPYs here and constrain the destination
    // register by explicitly.

    // Constrain destination register for COPYs and PHIs
    if (I.isCopy() || I.isPHI())
      return selectCopy(I, MRI);

    return true;
  }

  // make sure no implicit operands are present
  if (I.getNumOperands() != I.getNumExplicitOperands()) {
    LLVM_DEBUG(
        dbgs() << "Generic instruction has unexpected implicit operands.\n");
    return false;
  }

  // Try the TableGen'ed implementation first
  if (selectImpl(I, *CoverageInfo))
    return true;

  switch (OpCode) {
  case TargetOpcode::G_ANYEXT:
  case TargetOpcode::G_SEXT:
  case TargetOpcode::G_SEXT_INREG:
  case TargetOpcode::G_ZEXT:
    return selectExt(I, MRI);
  case TargetOpcode::G_BRCOND:
    return selectBrCond(I, MRI);
  case TargetOpcode::G_BRINDIRECT:
    return selectBrIndirect(I, MRI);
  case TargetOpcode::G_BRJT:
    return selectBrJumpTable(I, MRI, MF);
  case TargetOpcode::G_CONSTANT:
  case TargetOpcode::G_FCONSTANT:
    return selectConstant(I, MRI);
  case TargetOpcode::G_FCMP:
    return selectFCmp(I, MRI);
  case TargetOpcode::G_FPEXT:
    return selectFPExt(I, MRI);
  case TargetOpcode::G_FPTRUNC:
    return selectFPTrunc(I, MRI);
  case TargetOpcode::G_FRAME_INDEX:
    return selectFrameIndex(I, MRI);
  case TargetOpcode::G_FREEZE:
    return selectFreeze(I, MRI);
  case TargetOpcode::G_GLOBAL_VALUE:
    return selectGlobalValue(I, MRI);
  case TargetOpcode::G_ICMP:
    return selectICmp(I, MRI);
  case TargetOpcode::G_IMPLICIT_DEF:
    return selectImplicitDef(I, MRI);
  case TargetOpcode::G_INTRINSIC_W_SIDE_EFFECTS:
    return selectIntrinsicWithSideEffects(I, MRI);
  case TargetOpcode::G_INTTOPTR:
  case TargetOpcode::G_PTRTOINT:
    return selectCopy(I, MRI);
  case TargetOpcode::G_MERGE_VALUES:
    return selectMerge(I, MRI);
  case TargetOpcode::G_LOAD:
  case TargetOpcode::G_SEXTLOAD:
  case TargetOpcode::G_ZEXTLOAD:
  case TargetOpcode::G_STORE:
    return selectLoadStore(I, MRI);
  case TargetOpcode::G_PTR_ADD:
    return selectPtrAdd(I, MRI);
  case TargetOpcode::G_SELECT:
    return selectSelect(I, MRI);
  case TargetOpcode::G_TRUNC:
    return selectTrunc(I, MRI);
  case TargetOpcode::G_UADDE:
  case TargetOpcode::G_USUBE:
    return selectAddSubE(I, MRI);
  case TargetOpcode::G_UADDO:
  case TargetOpcode::G_USUBO:
    return selectAddSubO(I, MRI);
  case TargetOpcode::G_UNMERGE_VALUES:
    return selectUnmerge(I, MRI);
  case TargetOpcode::G_VASTART:
    return selectVaStart(I, MF, MRI);
  default:
    break;
  }

  LLVM_DEBUG(dbgs() << "Encountered unsupported instruction.\n");
  return false;
}

void TriCoreInstructionSelector::emit32BitSext(
    MachineRegisterInfo &MRI, Register DstReg, Register SrcReg,
    unsigned SrcSize, MachineIRBuilder &MIRBuilder) const {
  // 32-bit sign extension is done by the extract instruction. This instruction
  // extracts a number of bits from a source register and sign-extends them.
  const auto ExtrMI = MIRBuilder.buildInstr(TriCore::EXTR_ddcc)
                          .addDef(DstReg)
                          .addUse(SrcReg)
                          .addImm(0)
                          .addImm(SrcSize);

  constrainSelectedInstRegOperands(*ExtrMI, TII, TRI, RBI);
}

void TriCoreInstructionSelector::emit32BitZext(
    MachineRegisterInfo &MRI, Register DstReg, Register SrcReg,
    unsigned SrcSize, MachineIRBuilder &MIRBuilder) const {
  // 32-bit zero-extension can be achieved with the insert instruction. This
  // instruction inserts a number of bits from the given immediate at a given
  // position in the target register. By inserting 0 into the upper bits
  // the source register is zero-extended.
  const auto InsertMI = MIRBuilder.buildInstr(TriCore::INSERT_ddccc)
                            .addDef(DstReg)
                            .addUse(SrcReg)
                            .addImm(0)
                            .addImm(SrcSize)
                            .addImm(32 - SrcSize);

  constrainSelectedInstRegOperands(*InsertMI, TII, TRI, RBI);
}

void TriCoreInstructionSelector::emit32BitMerge(
    ArrayRef<Register> SrcRegs, Register DstReg, MachineIRBuilder &MIRBuilder,
    MachineRegisterInfo &MRI) const {
  // Use the insert instruction to insert the source bits
  assert(!SrcRegs.empty() && SrcRegs.size() % 2 == 0 &&
         "Unexpected number of source registers for 32-bit G_MERGE_VALUES");
  assert((MRI.getRegClassOrNull(DstReg) ||
          MRI.getType(DstReg).getSizeInBits() <= 32) &&
         "Unexpected destination type size");

  const LLT SrcTy = MRI.getType(SrcRegs[0]);
  const unsigned SrcSize = SrcTy.getSizeInBits();

  // We need to start with one IMPLICIT_DEF to insert from/to
  // If this merge is to a type smaller than 32-bits the upper bits will be
  // undefined when we are done. This is however not a problem as consuming
  // instruction will make sure that a proper extension is used or the consuming
  // instruction does not care about the upper bits (e.g. store half-word)
  Register InsertReg = MRI.createVirtualRegister(&TriCore::DataRegsRegClass);
  MIRBuilder.buildInstr(TargetOpcode::IMPLICIT_DEF).addDef(InsertReg);

  // Build one insert instruction per source register
  const unsigned NumSrcRegs = SrcRegs.size();
  for (unsigned i = 0, Offset = 0; i < NumSrcRegs; ++i, Offset += SrcSize) {
    // Current source register and destination register
    const Register SrcReg = SrcRegs[i];
    const Register DestReg =
        i == NumSrcRegs - 1
            ? DstReg
            : MRI.createVirtualRegister(&TriCore::DataRegsRegClass);

    // Insert SrcSize bits into DestReg starting at Offset, using bits from
    // InsertReg and SrcReg
    const auto InsertMI = MIRBuilder.buildInstr(TriCore::INSERT_dddcc)
                              .addDef(DestReg)
                              .addUse(InsertReg)
                              .addUse(SrcReg)
                              .addImm(Offset)
                              .addImm(SrcSize);

    constrainSelectedInstRegOperands(*InsertMI, TII, TRI, RBI);

    // Previous destination becomes new source
    InsertReg = DestReg;
  }
}

void TriCoreInstructionSelector::emit32BitUnmerge(
    Register SrcReg, ArrayRef<Register> DstRegs, MachineIRBuilder &MIRBuilder,
    const MachineRegisterInfo &MRI) const {
  // Use the extract instruction to get the required bits from the source reg
  assert(
      !DstRegs.empty() && DstRegs.size() % 2 == 0 &&
      "Unexpected number of destination registers for 32-bit G_UNMERGE_VALUES");
  assert((MRI.getRegClassOrNull(SrcReg) ||
          MRI.getType(SrcReg).getSizeInBits() <= 32) &&
         "Unexpected source type size");

  const LLT DstTy = MRI.getType(DstRegs[0]);
  const unsigned DstSize = DstTy.getSizeInBits();

  // Build one extract instruction per destination register
  const unsigned NumDstRegs = DstRegs.size();
  for (unsigned i = 0, Offset = 0; i < NumDstRegs; ++i, Offset += DstSize) {
    // Extract DstSize bits into DstReg from SrcReg starting at Offset
    const Register DstReg = DstRegs[i];

    const auto ExtrMI = MIRBuilder.buildInstr(TriCore::EXTR_ddcc)
                            .addDef(DstReg)
                            .addUse(SrcReg)
                            .addImm(Offset)
                            .addImm(DstSize);

    constrainSelectedInstRegOperands(*ExtrMI, TII, TRI, RBI);
  }
}

bool TriCoreInstructionSelector::selectAddSubE(MachineInstr &I,
                                               MachineRegisterInfo &MRI) const {
  assert(I.getOpcode() == TargetOpcode::G_UADDE ||
         I.getOpcode() == TargetOpcode::G_USUBE);

  const bool IsAdd = I.getOpcode() == TargetOpcode::G_UADDE;

  const Register &DstReg = I.getOperand(0).getReg();
  const Register &CarryOutReg = I.getOperand(1).getReg();
  const Register &Src1Reg = I.getOperand(2).getReg();
  const Register &Src2Reg = I.getOperand(3).getReg();
  Register CarryInReg = I.getOperand(4).getReg();

  const LLT DstTy = MRI.getType(DstReg);
  const LLT CarryTy = MRI.getType(CarryOutReg);

  // Add/sub /w carry requires 32-bit operands with 1-bit carries
  const std::string OpStr = IsAdd ? "G_UADDO" : "G_USUBO";
  if (!checkType(LLT::scalar(32), DstTy, OpStr) ||
      !checkType(LLT::scalar(1), CarryTy, OpStr))
    return false;

  // We have no way to simply materialize the carry bit in the PSW. Therefore
  // we must make sure that the carry-in comes from a carry-out producing
  // instruction. If that is not the case, the carry-in must be the constant
  // 0, since we can use a simple ADDX/SUBX instruction to handle this case.
  //
  // We also need to make sure that all usages of the carry-out are not
  // clobbered by other instructions.
  if (isCarryOutClobberedBeforeUse(I, MRI)) {
    LLVM_DEBUG(dbgs() << "Carry-out register is clobbered before use\n");
    return false;
  }

  // Also check if we can replace all uses of CarryOutReg with $psw_c
  const RegisterBank *CarryOutRB = MRI.getRegBankOrNull(CarryOutReg);
  if (!CarryOutRB || CarryOutRB->getID() != TriCore::StatusRegBankID) {
    LLVM_DEBUG(dbgs() << "Cannot replace " << CarryOutReg << " with "
                      << Register(TriCore::PSW_C)
                      << "because it is not assigned to the StatusRegBank\n");
    return false;
  }

  // Look for the definition of the carry-in register, skipping truncations and
  // virtual copies
  const MachineInstr *Def = getDefIgnoringCopies(CarryInReg, MRI);
  while ((Def->getOpcode() == TargetOpcode::G_TRUNC ||
          Def->getOpcode() == TargetOpcode::COPY) &&
         Def->getOperand(1).getReg().isVirtual()) {
    CarryInReg = Def->getOperand(1).getReg();
    Def = getDefIgnoringCopies(CarryInReg, MRI);
  }

  MachineIRBuilder MIRBuilder(I);

  // Check if the carry in register comes from a carry-out producing
  // instruction or is a constant
  unsigned Opc;
  if (isCarryOutProducer(*Def)) {
    // Def is a carry-out producer, i.e. it sets $psw_c. Use ADDC_ddd/SUBC_ddd
    // which read $psw_c.
    Opc = IsAdd ? TriCore::ADDC_ddd : TriCore::SUBC_ddd;

  } else if (auto CarryInVal = getConstantVRegVal(CarryInReg, MRI)) {
    // Carry-in is a constant. Check if it is 0
    if (*CarryInVal != 0) {
      LLVM_DEBUG(
          dbgs() << OpStr
                 << " with constant non-zero carry-in is not supported\n");
      return false;
    }

    Opc = IsAdd ? TriCore::ADDX_ddd : TriCore::SUBX_ddd;

  } else {
    // Carry-in comes from an unsupported source
    LLVM_DEBUG(
        dbgs()
        << "Carry-in from " << OpStr
        << " must be from carry-out producing instruction or constant 0\n");
    return false;
  }

  // Build target instruction and replace all uses of CarryOutReg with $psw_c
  const auto AddSubMI =
      MIRBuilder.buildInstr(Opc).addDef(DstReg).addUse(Src1Reg).addUse(Src2Reg);

  MRI.replaceRegWith(CarryOutReg, TriCore::PSW_C);

  constrainSelectedInstRegOperands(*AddSubMI, TII, TRI, RBI);

  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectAddSubO(MachineInstr &I,
                                               MachineRegisterInfo &MRI) const {
  assert(I.getOpcode() == TargetOpcode::G_UADDO ||
         I.getOpcode() == TargetOpcode::G_USUBO);

  const bool IsAdd = I.getOpcode() == TargetOpcode::G_UADDO;

  const Register &DstReg = I.getOperand(0).getReg();
  const Register &CarryReg = I.getOperand(1).getReg();
  const Register &Src1Reg = I.getOperand(2).getReg();
  const Register &Src2Reg = I.getOperand(3).getReg();

  const LLT DstTy = MRI.getType(DstReg);
  const LLT CarryTy = MRI.getType(CarryReg);

  // Add/sub /w carry requires 32-bit operands with 1-bit carry
  const std::string OpStr = IsAdd ? "G_UADDO" : "G_USUBO";
  if (!checkType(LLT::scalar(32), DstTy, OpStr) ||
      !checkType(LLT::scalar(1), CarryTy, OpStr))
    return false;

  // We need to make sure that all usages of the carry-out are not
  // clobbered by other instructions.
  if (isCarryOutClobberedBeforeUse(I, MRI)) {
    LLVM_DEBUG(dbgs() << "Carry-out register is clobbered before use\n");
    return false;
  }

  // Also check if we can replace all uses of CarryOutReg with $psw_c
  const RegisterBank *CarryOutRB = MRI.getRegBankOrNull(CarryReg);
  if (!CarryOutRB || CarryOutRB->getID() != TriCore::StatusRegBankID) {
    LLVM_DEBUG(dbgs() << "Cannot replace " << CarryReg << " with "
                      << Register(TriCore::PSW_C)
                      << "because it is not assigned to the StatusRegBank\n");
    return false;
  }

  // Emit ADDX/SUBX and replace CarryReg with $psw_c
  MachineIRBuilder MIRBuilder(I);

  const unsigned Opc = IsAdd ? TriCore::ADDX_ddd : TriCore::SUBX_ddd;
  const auto AddSubMI =
      MIRBuilder.buildInstr(Opc).addDef(DstReg).addUse(Src1Reg).addUse(Src2Reg);

  MRI.replaceRegWith(CarryReg, TriCore::PSW_C);

  constrainSelectedInstRegOperands(*AddSubMI, TII, TRI, RBI);

  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectBrCond(
    MachineInstr &I, const MachineRegisterInfo &MRI) const {
  // Check for correct type
  const LLT &Ty = MRI.getType(I.getOperand(0).getReg());
  if (Ty.getSizeInBits() > 32) {
    LLVM_DEBUG(dbgs() << "G_BRCOND has type " << Ty
                      << ", expected at most 32-bits.\n");
    return false;
  }

  MachineIRBuilder MIRBuilder(I);

  // Check if we can select a compare-and-jump
  if (selectCmpAndJump(I, MRI, MIRBuilder))
    return true;

  // Change to JNE/JNE.A 0 depending on register bank
  const Register &CondReg = I.getOperand(0).getReg();
  const RegisterBank *CondRB = RBI.getRegBank(CondReg, MRI, TRI);

  if (!CondRB) {
    LLVM_DEBUG(dbgs() << "Could not determine register bank for G_BRCOND");
    return false;
  }

  const bool isAddrRB = CondRB->getID() == TriCore::AddrRegBankID;
  const unsigned OpCode = isAddrRB ? TriCore::JNZA_ac : TriCore::JNE_dcc;

  MachineBasicBlock *MBB = I.getOperand(1).getMBB();
  auto JumpMI = MIRBuilder.buildInstr(OpCode).addUse(CondReg);

  // There is no JNEA_acc and equally no JNZ_dc instruction. We could use 16-bit
  // variants to get rid of the immediate, however these have the downside of
  // only having a short range and needing an implicit register. Therefore we
  // use the 32-bit variants and need to add the 0 immediate conditionally.
  if (!isAddrRB)
    JumpMI = JumpMI.addImm(0);

  JumpMI = JumpMI.addMBB(MBB);
  constrainSelectedInstRegOperands(*JumpMI, TII, TRI, RBI);

  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectBrIndirect(
    MachineInstr &I, const MachineRegisterInfo &MRI) const {
  const LLT &Ty = MRI.getType(I.getOperand(0).getReg());
  if (!checkType(LLT::pointer(0, 32), Ty, "G_BRINDIRECT"))
    return false;

  // Change to JI
  I.setDesc(TII.get(TriCore::JI));
  constrainSelectedInstRegOperands(I, TII, TRI, RBI);
  return true;
}

bool TriCoreInstructionSelector::selectBrJumpTable(
    MachineInstr &I, MachineRegisterInfo &MRI,
    const MachineFunction &MF) const {
  assert(I.getOpcode() == TargetOpcode::G_BRJT);
  assert(I.getOperand(1).isJTI() &&
         "Expected operand 1 of G_BRJT to be a jump table index");

  // G_BRJT jumps to the jump table at the specified index. The first register
  // is a pointer to the beginning of the jump table while the third register
  // is a scalar offset inside the jump table.
  // The second operand is a jump table index operand. It is present since
  // some targets can use it for easier optimization.
  //
  // The pointer input for G_BRJT should always be a G_JUMP_TABLE. We want to
  // combine both of them into a single pseudo instruction. Therefore we need to
  // check that our assumption is true.
  //
  // G_BRJT is lowered to a pseudo instruction which calculates the address of
  // and jumps to the jump table
  const Register PtrReg = I.getOperand(0).getReg();
  const Register OffReg = I.getOperand(2).getReg();
  const int JTI = I.getOperand(1).getIndex();

  // Check that the PtrReg is coming from a G_JUMP_TABLE instruction
  MachineInstr *PtrDef = MRI.getVRegDef(PtrReg);
  while (PtrDef) {
    const Register PtrDefReg = PtrDef->getOperand(0).getReg();

    // Make sure that we have only one usage, then continue
    if (!MRI.hasOneUse(PtrDefReg)) {
      LLVM_DEBUG(
          dbgs() << "Pointer input to G_BRJT must have exactly one usage\n");
      return false;
    }

    if (PtrDef->getOpcode() == TargetOpcode::G_JUMP_TABLE) {
      // We should have the same JTI
      assert((PtrDef->getOperand(1).getIndex()) == JTI &&
             "Jump table index of G_BRJT and G_JUMP_TABLE do not match?!");
      break;
    }

    // Ignore COPYs
    if (PtrDef->getOpcode() == TargetOpcode::COPY)
      PtrDef = MRI.getVRegDef(PtrDef->getOperand(1).getReg());
    else {
      // No idea what input we have
      LLVM_DEBUG(dbgs() << "Unknown pointer input to G_BRJT:\n" << *PtrDef);
      return false;
    }
  }

  const LLT PtrTy = MRI.getType(PtrReg);
  const LLT OffTy = MRI.getType(OffReg);

  const std::string OpcString = "G_BRJT";
  if (!checkType(LLT::pointer(0, 32), PtrTy, OpcString) ||
      !checkType(LLT::scalar(32), OffTy, OpcString))
    return false;

  // Check register bank
  const RegisterBank &PtrRB = *RBI.getRegBank(PtrReg, MRI, TRI);
  const RegisterBank &OffRB = *RBI.getRegBank(OffReg, MRI, TRI);

  if (PtrRB.getID() != TriCore::AddrRegBankID ||
      OffRB.getID() != TriCore::DataRegBankID) {
    LLVM_DEBUG(dbgs() << "Unexpected regbank for G_BRJT. PtrRB: " << PtrRB
                      << ", OffRB: " << OffRB << '\n');
    return false;
  }

  const bool IsPIC = MF.getTarget().isPositionIndependent();
  const bool HasJRI = MF.getSubtarget<TriCoreSubtarget>().hasTC18Ops();

  // We need to use a different pseudo if we have PIC and the JRI instruction is
  // not available
  const unsigned Opcode =
      IsPIC && !HasJRI ? TriCore::JIJumpTableTC16XPIC : TriCore::JIJumpTable;

  MachineIRBuilder MIRBuilder(I);

  // Scratch registers
  const Register PtrOffReg =
      MRI.createVirtualRegister(&TriCore::AddrRegsRegClass);

  // Emit JIJumpTable pseudo, which is later lowered to ADDSC.A + JI
  const auto JiMI = MIRBuilder.buildInstr(Opcode).addDef(PtrOffReg);

  // We need a second def register if JIJumpTableTC16XPIC is used
  if (Opcode == TriCore::JIJumpTableTC16XPIC) {
    const Register ScratchReg =
        MRI.createVirtualRegister(&TriCore::AddrRegsRegClass);
    JiMI.addDef(ScratchReg);
  }

  // Add the index and the jump table operand
  JiMI.addUse(OffReg)
      .addJumpTableIndex(JTI, TriCoreII::MO_HI)
      .addJumpTableIndex(JTI, TriCoreII::MO_LO);

  constrainSelectedInstRegOperands(*JiMI, TII, TRI, RBI);

  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectConstant(
    MachineInstr &I, MachineRegisterInfo &MRI) const {

  const bool IsFloat = I.getOpcode() == TargetOpcode::G_FCONSTANT;

  const Register DstReg = I.getOperand(0).getReg();
  const LLT Ty = MRI.getType(DstReg);
  const unsigned DefSize = Ty.getSizeInBits();
  const RegisterBank &DstRB = *RBI.getRegBank(DstReg, MRI, TRI);

  if (DefSize != 16 && DefSize != 32 && DefSize != 64) {
    LLVM_DEBUG(dbgs() << "Constant with unsupported size.\n");
    return false;
  }

  // Get the concrete value of this constant.
  const MachineOperand &ImmOp = I.getOperand(1);
  uint64_t Val;
  if (IsFloat) {
    Val = ImmOp.getFPImm()->getValueAPF().bitcastToAPInt().getLimitedValue();
  } else if (ImmOp.isCImm()) {
    Val = ImmOp.getCImm()->getZExtValue();
  } else if (ImmOp.isImm()) {
    Val = ImmOp.getImm();
  } else {
    LLVM_DEBUG(dbgs() << "Unsupported immediate type.\n");
    return false;
  }
  MachineIRBuilder MIRBuilder(I);

  unsigned MovOpcode = 0;
  if (DstRB.getID() == TriCore::AddrRegBankID) {
    // TODO: support 64-bit constants on the address register bank
    if (DefSize != 32) {
      LLVM_DEBUG(dbgs() << "64-bit constants on the address register bank are "
                           "not supported yet.\n");
      return false;
    }
    MovOpcode = TriCore::MOVImmAddrReg;

  } else if (DstRB.getID() == TriCore::DataRegBankID) {

    if (DefSize == 64)
      MovOpcode = TriCore::MOVImmExtDataReg;
    else
      MovOpcode = TriCore::MOVImmDataReg;

  } else {
    LLVM_DEBUG(dbgs() << "G_CONSTANT on unexpected register bank: " << DstRB
                      << ".\n");
    return false;
  }

  auto MovImm = MIRBuilder.buildInstr(MovOpcode)
                    .addDef(I.getOperand(0).getReg())
                    .addImm(Val);
  constrainSelectedInstRegOperands(*MovImm, TII, TRI, RBI);
  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectCmpAndJump(
    MachineInstr &I, const MachineRegisterInfo &MRI,
    MachineIRBuilder &MIRBuilder) const {

  const Register CondReg = I.getOperand(0).getReg();
  MachineBasicBlock *const DestMBB = I.getOperand(1).getMBB();
  MachineInstr *CondMI = MRI.getVRegDef(CondReg);

  // Check for G_ICMP, skipping a G_TRUNC
  if (CondMI->getOpcode() == TargetOpcode::G_TRUNC)
    CondMI = MRI.getVRegDef(CondMI->getOperand(1).getReg());

  if (CondMI->getOpcode() != TargetOpcode::G_ICMP)
    return false;

  const MachineOperand &Predicate = CondMI->getOperand(1);
  auto P = (CmpInst::Predicate)Predicate.getPredicate();

  const Register &SrcReg = CondMI->getOperand(2).getReg();
  const RegisterBank *RB = RBI.getRegBank(SrcReg, MRI, TRI);

  if (!RB) {
    LLVM_DEBUG(
        dbgs() << "Could not determine register bank for source register.\n");
    return false;
  }

  bool SwapOperands = false;
  unsigned JumpOpCode = getBranchOpCodeForPredicate(P, *RB, SwapOperands);

  if (JumpOpCode == 0) {
    // Cannot select compare-and-jump. Fall back to normal selection
    return false;
  }

  unsigned LHSIdx = SwapOperands ? 3 : 2;
  unsigned RHSIdx = SwapOperands ? 2 : 3;

  const Register LHS = CondMI->getOperand(LHSIdx).getReg();
  const Register RHS = CondMI->getOperand(RHSIdx).getReg();

  // Check if the right-hand-side operand is a constant, in which case we might
  // be able to fold it into the instruction
  MachineInstr *JumpMI;
  auto VRegAndVal = getConstantVRegValWithLookThrough(RHS, MRI);
  if (VRegAndVal) {
    int64_t C = VRegAndVal->Value;
    if (unsigned ImmCmpOpc = getCompareWithImmediateOpcode(JumpOpCode, C)) {
      JumpMI = MIRBuilder.buildInstr(ImmCmpOpc).addUse(LHS).addImm(C).addMBB(DestMBB);
      constrainSelectedInstRegOperands(*JumpMI, TII, TRI, RBI);
      I.removeFromParent();
      return true;
    }
  }

  // Nothing to fold, build the compare-and-jump instruction
  JumpMI =
    MIRBuilder.buildInstr(JumpOpCode).addUse(LHS).addUse(RHS).addMBB(DestMBB);
  constrainSelectedInstRegOperands(*JumpMI, TII, TRI, RBI);
  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectImplicitDef(
    MachineInstr &I, MachineRegisterInfo &MRI) const {

  assert(I.getOpcode() == TargetOpcode::G_IMPLICIT_DEF);

  const Register DstReg = I.getOperand(0).getReg();
  const LLT DstTy = MRI.getType(DstReg);
  const RegisterBank &DstRB = *RBI.getRegBank(DstReg, MRI, TRI);
  const TargetRegisterClass *DstRC = getRegClassForTypeOnBank(DstTy, DstRB);

  if (!DstRC) {
    LLVM_DEBUG(
        dbgs()
        << "Unable to determine TargetRegisterClass for G_IMPLICIT_DEF\n");
    return false;
  }

  TriCoreRegisterBankInfo::constrainGenericRegister(DstReg, *DstRC, MRI);
  I.setDesc(TII.get(TargetOpcode::IMPLICIT_DEF));

  return true;
}

bool TriCoreInstructionSelector::selectCopy(MachineInstr &I,
                                            MachineRegisterInfo &MRI) const {
  const unsigned Opc = I.getOpcode();
  assert((Opc == TargetOpcode::COPY || Opc == TargetOpcode::PHI ||
          Opc == TargetOpcode::G_PHI || Opc == TargetOpcode::G_INTTOPTR ||
          Opc == TargetOpcode::G_PTRTOINT) &&
         "Unexpected instruction");

  // Constrain the destination register for COPY, G_PHI and PHI

  // COPY requires SrcReg and DstReg to have matching types:
  //    if the type is still available:
  //      types must match
  //    if one of the operands has a register class set:
  //      other operand must have the same size as the register class
  //
  // Therefore we can only have the following COPYs:
  //    %1:*regbank(s*) = COPY %0:*regbank(s*)
  //
  //    %1:*regbank(s32) = COPY %0:{addr,data}regs
  //
  //    %1:{addr,data}regs = COPY %0:*regbank(s32)
  //
  //    %1:{addr,data}regs = COPY %0:{addr,data}regs
  //
  //    %1:ext{addr,data}regs = COPY %0:ext{addr,data}regs
  //
  // The following COPYs are not possible (given different register banks for
  // the 2nd example)
  //    %1:ext{addr,data}regs = COPY %0:*regbank(s32)
  // Because s32 has 32-bits but the destination is 64 bits and
  //
  //    %1:*regbank(s32) = COPY %0:ext{addr,data}regs.SubRegIdx
  // Because we are the only one who can emit a subregister copy and in that
  // case we make sure that the register banks are the same
  //
  // All other instructions that are selected to a COPY/PHI are also legalized
  // to have the same type size.
  //
  // Therefore we can be sure that SrcSize and DstSize are the same

  const Register DstReg = I.getOperand(0).getReg();
  const Register SrcReg = I.getOperand(1).getReg();
  unsigned DstSize = RBI.getSizeInBits(DstReg, MRI, TRI);
  unsigned SrcSize = RBI.getSizeInBits(SrcReg, MRI, TRI);

  assert(DstSize == SrcSize && "Unexpected illegal subregister copy");

  // Find the correct register classes for the source and destination registers.
  const RegisterBank &DstRegBank = *RBI.getRegBank(DstReg, MRI, TRI);
  const TargetRegisterClass *DstRC = getRegClassForRegBank(DstRegBank, DstSize);

  if (!DstRC) {
    LLVM_DEBUG(dbgs() << "Unexpected register size " << DstSize << '\n');
    return false;
  }

  // Set the expected OpCode: PHI for G_PHI, COPY for anything else
  const unsigned OpCode = I.isPHI() ? TargetOpcode::PHI : TargetOpcode::COPY;
  I.setDesc(TII.get(OpCode));

  // Nothing to do if DstReg is a physical register
  if (Register::isPhysicalRegister(DstReg))
    return true;

  // And constrain the destination. No need to constrain the source register
  // as it will be constrained once we reach another of its uses or defs.
  if (!TriCoreRegisterBankInfo::constrainGenericRegister(DstReg, *DstRC, MRI)) {
    LLVM_DEBUG(
        dbgs() << "Failed to constrain COPY/G_PHI/PHI destination operand\n");
    return false;
  }

  return true;
}

bool TriCoreInstructionSelector::selectExt(MachineInstr &I,
                                           MachineRegisterInfo &MRI) const {
  const bool IsSignedInReg = I.getOpcode() == TargetOpcode::G_SEXT_INREG;
  const bool IsSigned = I.getOpcode() == TargetOpcode::G_SEXT || IsSignedInReg;
  const bool IsAnyExt = I.getOpcode() == TargetOpcode::G_ANYEXT;

  const Register DstReg = I.getOperand(0).getReg();
  const Register SrcReg = I.getOperand(1).getReg();

  const LLT DstTy = MRI.getType(DstReg);
  const LLT SrcTy = MRI.getType(SrcReg);

  const unsigned DstSize = DstTy.getSizeInBits();
  const unsigned SrcSize =
      IsSignedInReg ? I.getOperand(2).getImm() : SrcTy.getSizeInBits();

  if (DstSize != 32 && DstSize != 64) {
    LLVM_DEBUG(dbgs() << "Extension has type " << DstTy << ", but expected "
                      << LLT::scalar(32) << " or " << LLT::scalar(64) << '\n');
    return false;
  }

  const RegisterBank *DstRB = RBI.getRegBank(DstReg, MRI, TRI);
  const RegisterBank *SrcRB = RBI.getRegBank(SrcReg, MRI, TRI);

  if (!DstRB || DstRB->getID() != TriCore::DataRegBankID || !SrcRB ||
      SrcRB->getID() != TriCore::DataRegBankID) {
    LLVM_DEBUG(dbgs() << "Unexpected register bank for extension\n");
    return false;
  }

  if (IsAnyExt)
    return selectExtAny(I, MRI, DstSize, SrcSize);
  else if (IsSigned)
    return selectExtSign(I, MRI, DstSize, SrcSize);
  else
    return selectExtZero(I, MRI, DstSize, SrcSize);
}

bool TriCoreInstructionSelector::selectExtAny(MachineInstr &I,
                                              MachineRegisterInfo &MRI,
                                              unsigned DstSize,
                                              unsigned SrcSize) const {
  assert(I.getOpcode() == TargetOpcode::G_ANYEXT);

  const Register DstReg = I.getOperand(0).getReg();
  const Register SrcReg = I.getOperand(1).getReg();

  // Select to COPY if we stay within the same register
  if (DstSize == 32 || SrcSize > 32) {
    I.setDesc(TII.get(TargetOpcode::COPY));

    const TargetRegisterClass &RC =
        SrcSize > 32 ? TriCore::ExtDataRegsRegClass : TriCore::DataRegsRegClass;

    TriCoreRegisterBankInfo::constrainGenericRegister(DstReg, RC, MRI);
    TriCoreRegisterBankInfo::constrainGenericRegister(SrcReg, RC, MRI);
    return true;
  }

  assert(DstSize == 64 && "Unexpected destination size for G_ANYEXT");
  assert(SrcSize <= 32 && "Unexpected source size for G_ANYEXT");

  MachineIRBuilder MIRBuilder(I);

  // For 64-bit we can do the following:
  //
  // %e = IMPLICIT_DEF
  // %e = INSERT_SUBREG %e, %src, dsub0
  const Register ExtReg =
      MRI.createVirtualRegister(&TriCore::ExtDataRegsRegClass);

  // Use implicit-def to get an undefined 64-bit register, then insert subreg
  MIRBuilder.buildInstr(TargetOpcode::IMPLICIT_DEF).addDef(ExtReg);

  // Insert into lower bits
  MIRBuilder.buildInstr(TargetOpcode::INSERT_SUBREG)
      .addDef(DstReg)
      .addUse(ExtReg)
      .addUse(SrcReg)
      .addImm(TriCore::dsub0);

  TriCoreRegisterBankInfo::constrainGenericRegister(
      DstReg, TriCore::ExtDataRegsRegClass, MRI);
  TriCoreRegisterBankInfo::constrainGenericRegister(
      ExtReg, TriCore::ExtDataRegsRegClass, MRI);
  TriCoreRegisterBankInfo::constrainGenericRegister(
      SrcReg, TriCore::DataRegsRegClass, MRI);

  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectExtSign(MachineInstr &I,
                                               MachineRegisterInfo &MRI,
                                               unsigned DstSize,
                                               unsigned SrcSize) const {
  assert(I.getOpcode() == TargetOpcode::G_SEXT ||
         I.getOpcode() == TargetOpcode::G_SEXT_INREG);

  const Register DstReg = I.getOperand(0).getReg();
  Register SrcReg = I.getOperand(1).getReg();

  MachineIRBuilder MIRBuilder(I);

  if (DstSize == 32) {
    emit32BitSext(MRI, DstReg, SrcReg, SrcSize, MIRBuilder);
    I.removeFromParent();
    return true;
  }

  assert(DstSize == 64 && "Unexpected destination size for sign-extend");

  // For 64-bits we can do the following:
  //
  // Source size 32-bits:
  // mul %e, %d, 1
  //
  // Source size < 32-bits:
  // extr %dn, %d, 0, SrcSize
  // sha %dk, %dn, -31
  // REG_SEQUENCE %dn, dsub0, %dk, dsub1
  //
  // Source size > 32-bits:
  // same as 32-bit destination for upper subreg

  // In case of G_SEXT_INREG, our SrcReg is a 64-bit register as well. We need
  // the 32-bit subregister if SrcSize is within 32-bit
  if (SrcSize <= 32 && MRI.getType(SrcReg).getSizeInBits() > 32) {
    assert(I.getOpcode() == TargetOpcode::G_SEXT_INREG &&
           "Expected G_SEXT_INREG if SrcSize and type of SrcReg differ!");
    const Register ScratchReg =
        MRI.createVirtualRegister(&TriCore::DataRegsRegClass);

    // No need to constrain SextSubreg since it already has a register
    // class and will be constrained again by emit32BitSext
    MIRBuilder.buildInstr(TargetOpcode::COPY)
        .addDef(ScratchReg)
        .addUse(SrcReg, 0, TriCore::dsub0);

    SrcReg = ScratchReg;
  }

  if (SrcSize == 32) {
    // This sign extends the result and puts it into a 64-bit register
    const auto MulMI = MIRBuilder.buildInstr(TriCore::MUL_edc)
                           .addDef(DstReg)
                           .addUse(SrcReg)
                           .addImm(1);

    constrainSelectedInstRegOperands(*MulMI, TII, TRI, RBI);

  } else if (SrcSize < 32) {
    // Temporary registers
    const Register ExtrReg =
        MRI.createVirtualRegister(&TriCore::DataRegsRegClass);
    const Register ShaReg =
        MRI.createVirtualRegister(&TriCore::DataRegsRegClass);

    // Sign-extend the source register to 32-bit
    emit32BitSext(MRI, ExtrReg, SrcReg, SrcSize, MIRBuilder);

    // This sets the the upper 32 bits to either 0 or 1
    const auto ShaMI = MIRBuilder.buildInstr(TriCore::SHA_ddc)
                           .addDef(ShaReg)
                           .addUse(ExtrReg)
                           .addImm(-31);

    // Merge to extended register
    MIRBuilder.buildInstr(TriCore::REG_SEQUENCE)
        .addDef(DstReg)
        .addUse(ExtrReg)
        .addImm(TriCore::dsub0)
        .addUse(ShaReg)
        .addImm(TriCore::dsub1);

    constrainSelectedInstRegOperands(*ShaMI, TII, TRI, RBI);

    if (!TriCoreRegisterBankInfo::constrainGenericRegister(
            DstReg, TriCore::ExtDataRegsRegClass, MRI)) {
      LLVM_DEBUG(
          dbgs() << "Failed to constrain destination register for G_SEXT\n");
      return false;
    }

  } else {
    // Source and destination register for the upper bits
    const Register UpperReg =
        MRI.createVirtualRegister(&TriCore::DataRegsRegClass);
    const Register UpperDstReg =
        MRI.createVirtualRegister(&TriCore::DataRegsRegClass);

    // Extract the upper bits
    MIRBuilder.buildInstr(TriCore::COPY)
        .addDef(UpperReg)
        .addUse(SrcReg, 0, TriCore::dsub1);

    // Emit a 32-bit sign-extension for the upper bits
    emit32BitSext(MRI, UpperDstReg, UpperReg, SrcSize - 32, MIRBuilder);

    // Replace the original upper bits with the sign-extended upper bits
    MIRBuilder.buildInstr(TargetOpcode::INSERT_SUBREG)
        .addDef(DstReg)
        .addUse(SrcReg)
        .addUse(UpperDstReg)
        .addImm(TriCore::dsub1);

    // UpperReg, UpperDstReg already constrained by emit32BitSext
    if (!TriCoreRegisterBankInfo::constrainGenericRegister(
            DstReg, TriCore::ExtDataRegsRegClass, MRI) ||
        !TriCoreRegisterBankInfo::constrainGenericRegister(
            SrcReg, TriCore::ExtDataRegsRegClass, MRI)) {
      LLVM_DEBUG(
          dbgs()
          << "Failed to constrain destination or source register for G_SEXT\n");
      return false;
    }
  }

  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectExtZero(MachineInstr &I,
                                               MachineRegisterInfo &MRI,
                                               unsigned DstSize,
                                               unsigned SrcSize) const {
  assert(I.getOpcode() == TargetOpcode::G_ZEXT);

  const Register DstReg = I.getOperand(0).getReg();
  const Register SrcReg = I.getOperand(1).getReg();

  MachineIRBuilder MIRBuilder(I);

  // If the destination size is 32-bits we can use insert. A bit-mask might be
  // too big for the immediate of the AND instruction
  if (DstSize == 32) {
    emit32BitZext(MRI, DstReg, SrcReg, SrcSize, MIRBuilder);
    I.removeFromParent();
    return true;
  }

  assert(DstSize == 64 && "Unexpected destination size for zero-extend");

  // For 64-bits we can do the following:
  //
  // Source size <= 32-bits:
  // %lower = zero-extend %src
  // %upper = MOV 0
  // %e = REG_SEQUENCE %lower, dsub0, %upper, dsub1
  //
  // Source size > 32-bits:
  // same as 32-bit for upper subreg
  if (SrcSize <= 32) {
    Register LowerExtReg = SrcReg;

    if (SrcSize < 32) {
      // Zero-extend the lower register to 32-bit if necessary
      LowerExtReg = MRI.createVirtualRegister(&TriCore::DataRegsRegClass);
      emit32BitZext(MRI, LowerExtReg, SrcReg, SrcSize, MIRBuilder);
    }

    const Register ZeroReg =
        MRI.createVirtualRegister(&TriCore::DataRegsRegClass);

    // Set the upper subregister to 0
    MIRBuilder.buildInstr(TriCore::MOV_dc).addDef(ZeroReg).addImm(0);

    // Merge to 64-bit register
    MIRBuilder.buildInstr(TargetOpcode::REG_SEQUENCE)
        .addDef(DstReg)
        .addUse(LowerExtReg)
        .addImm(TriCore::dsub0)
        .addUse(ZeroReg)
        .addImm(TriCore::dsub1);

    if (!TriCoreRegisterBankInfo::constrainGenericRegister(
            DstReg, TriCore::ExtDataRegsRegClass, MRI) ||
        !TriCoreRegisterBankInfo::constrainGenericRegister(
            LowerExtReg, TriCore::DataRegsRegClass, MRI)) {
      LLVM_DEBUG(dbgs() << "Failed to constrain destination or lower extension "
                           "register for G_ZEXT\n");
      return false;
    }

  } else {
    const Register UpperReg =
        MRI.createVirtualRegister(&TriCore::DataRegsRegClass);
    const Register UpperDstReg =
        MRI.createVirtualRegister(&TriCore::DataRegsRegClass);

    MIRBuilder.buildInstr(TargetOpcode::COPY)
        .addDef(UpperReg)
        .addUse(SrcReg, 0, TriCore::dsub1);

    // Zero-extend the upper subregister
    emit32BitZext(MRI, UpperDstReg, UpperReg, SrcSize - 32, MIRBuilder);

    // Replace the original upper-bits with the zero-extended ones
    MIRBuilder.buildInstr(TargetOpcode::INSERT_SUBREG)
        .addDef(DstReg)
        .addUse(SrcReg)
        .addUse(UpperDstReg)
        .addImm(TriCore::dsub1);

    if (!TriCoreRegisterBankInfo::constrainGenericRegister(
            DstReg, TriCore::ExtDataRegsRegClass, MRI) ||
        !TriCoreRegisterBankInfo::constrainGenericRegister(
            SrcReg, TriCore::ExtDataRegsRegClass, MRI)) {
      LLVM_DEBUG(
          dbgs()
          << "Failed to constrain destination or source register for G_ZEXT\n");
      return false;
    }
  }

  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectFrameIndex(
    MachineInstr &I, const MachineRegisterInfo &MRI) const {
  // G_FRAME_INDEX is only valid for p0 types and on address regbank
  const Register &DstReg = I.getOperand(0).getReg();
  const LLT Ty = MRI.getType(DstReg);

  if (!checkType(LLT::pointer(0, 32), Ty, "G_FRAME_INDEX"))
    return false;

  const RegisterBank *RB = RBI.getRegBank(DstReg, MRI, TRI);
  assert(RB && RB->getID() == TriCore::AddrRegBankID &&
         "Expected G_FRAME_INDEX to be on the address regbank");
  (void)RB; // silence unused variable warning in non-assert builds

  // Lower to LEA_aac 0. This will later be lowered again to the actual
  // stack-pointer computation.
  I.setDesc(TII.get(TriCore::LEA_aac));
  I.addOperand(MachineOperand::CreateImm(0));
  constrainSelectedInstRegOperands(I, TII, TRI, RBI);
  return true;
}

bool TriCoreInstructionSelector::selectFreeze(MachineInstr &I,
                                              MachineRegisterInfo &MRI) const {

  assert(I.getOpcode() == TargetOpcode::G_FREEZE);

  const Register DstReg = I.getOperand(0).getReg();
  const LLT DstTy = MRI.getType(DstReg);
  const RegisterBank &DstRB = *RBI.getRegBank(DstReg, MRI, TRI);
  const TargetRegisterClass *DstRC = getRegClassForTypeOnBank(DstTy, DstRB);

  if (!DstRC) {
    LLVM_DEBUG(
        dbgs() << "Unable to determine TargetRegisterClass for G_FREEZE\n");
    return false;
  }

  TriCoreRegisterBankInfo::constrainGenericRegister(DstReg, *DstRC, MRI);
  I.setDesc(TII.get(TargetOpcode::COPY));

  return true;
}

bool TriCoreInstructionSelector::selectFltRounds(
    MachineInstr &I, MachineRegisterInfo &MRI) const {
  Register DstReg = I.getOperand(0).getReg();
  Register MfcrResult = MRI.createVirtualRegister(&TriCore::DataRegsRegClass);
  Register AddihResult = MRI.createVirtualRegister(&TriCore::DataRegsRegClass);

  MachineIRBuilder MIRBuilder(I);

  // Move status register PSW to a data register
  auto Mfcr = MIRBuilder.buildInstr(TriCore::MFCR_dc)
                  .addDef(MfcrResult)
                  .addImm(TriCoreSysReg::psw)
                  .addUse(TriCore::PSW, RegState::Implicit);

  // Add 0x0100 to convert from TriCore format to C-Standard format
  auto Addih = MIRBuilder.buildInstr(TriCore::ADDIH_ddc)
                   .addDef(AddihResult)
                   .addUse(MfcrResult)
                   .addImm(0x0100);

  // Extract rounding mode bits (bits #24 and #25)
  auto Extru = MIRBuilder.buildInstr(TriCore::EXTRU_ddcc)
                   .addDef(DstReg)
                   .addUse(AddihResult)
                   .addImm(24)
                   .addImm(2);

  constrainSelectedInstRegOperands(*Mfcr, TII, TRI, RBI);
  constrainSelectedInstRegOperands(*Addih, TII, TRI, RBI);
  constrainSelectedInstRegOperands(*Extru, TII, TRI, RBI);

  I.eraseFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectFPExt(
    MachineInstr &I, const MachineRegisterInfo &MRI) const {
  Register DestReg = I.getOperand(0).getReg();
  Register SrcReg = I.getOperand(1).getReg();

  LLT DestTy = MRI.getType(DestReg);
  LLT SrcTy = MRI.getType(SrcReg);
  assert(DestTy == LLT::scalar(32) && SrcTy == LLT::scalar(16) &&
         "Single/Double precision extensions should have been handled in "
         "TableGen");

  MachineIRBuilder MIRBuilder(I);
  auto ConvInstr =
      MIRBuilder.buildInstr(TriCore::HPTOF_dd).addDef(DestReg).addUse(SrcReg);

  constrainSelectedInstRegOperands(*ConvInstr, TII, TRI, RBI);
  I.eraseFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectFPTrunc(
    MachineInstr &I, const MachineRegisterInfo &MRI) const {
  Register DestReg = I.getOperand(0).getReg();
  Register SrcReg = I.getOperand(1).getReg();

  LLT DestTy = MRI.getType(DestReg);
  LLT SrcTy = MRI.getType(SrcReg);
  assert(DestTy == LLT::scalar(16) && SrcTy == LLT::scalar(32) &&
         "Single/Double precision truncations should have been handled in "
         "TableGen");

  MachineIRBuilder MIRBuilder(I);
  auto ConvInstr =
      MIRBuilder.buildInstr(TriCore::FTOHP_dd).addDef(DestReg).addUse(SrcReg);

  constrainSelectedInstRegOperands(*ConvInstr, TII, TRI, RBI);
  I.eraseFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectGlobalValue(
    MachineInstr &I, MachineRegisterInfo &MRI) const {
  // TODO: add support for small data section

  // Lower to MOVH.A and LEA
  MachineIRBuilder MIRBuilder(I);

  const Register MovAReg =
      MRI.createVirtualRegister(&TriCore::AddrRegsRegClass);
  auto GV = I.getOperand(1).getGlobal();
  const unsigned Offset = I.getOperand(1).getOffset();

  auto MovHA = MIRBuilder.buildInstr(TriCore::MOVHA_ac)
                   .addDef(MovAReg)
                   .addGlobalAddress(GV, Offset, TriCoreII::MO_HI);

  auto Lea = MIRBuilder.buildInstr(TriCore::LEA_aac)
                 .addDef(I.getOperand(0).getReg())
                 .addUse(MovAReg)
                 .addGlobalAddress(GV, Offset, TriCoreII::MO_LO);

  constrainSelectedInstRegOperands(*MovHA, TII, TRI, RBI);
  constrainSelectedInstRegOperands(*Lea, TII, TRI, RBI);

  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectFCmp(MachineInstr &I,
                                            MachineRegisterInfo &MRI) const {

  // Check for the correct type
  Register DstReg = I.getOperand(0).getReg();
  const LLT &Ty = MRI.getType(DstReg);
  if (!checkType(LLT::scalar(32), Ty, "G_FCMP")) {
    return false;
  }

  MachineIRBuilder MIRBuilder(I);
  CmpInst::Predicate Pred =
      static_cast<CmpInst::Predicate>(I.getOperand(1).getPredicate());

  if (Pred == CmpInst::FCMP_TRUE || Pred == CmpInst::FCMP_FALSE) {
    // If we encounter the constant predicates, simply materialize the
    // respective constant.
    auto ConstInstr = MIRBuilder.buildInstr(TriCore::MOVU_dc)
                          .addDef(DstReg)
                          .addImm(Pred == CmpInst::FCMP_TRUE ? 1 : 0);
    I.eraseFromParent();
    return constrainSelectedInstRegOperands(*ConstInstr, TII, TRI, RBI);
  }

  // First create the floating point comparison instruction. It will output the
  // result in the lower 6 bits in the following way
  // bit [0] D[a] < D[b]
  // bit [1] D[a] == D[b]
  // bit [2] D[a] > D[b]
  // bit [3] Unordered
  // bit [4] D[a] is denormal
  // bit [5] D[b] is denormal
  LLT SrcTy = MRI.getType(I.getOperand(2).getReg());
  assert((SrcTy == LLT::scalar(32) || SrcTy == LLT::scalar(64)) &&
         "Only 32 and 64-bit floats are supported");
  unsigned Opcode =
      SrcTy == LLT::scalar(32) ? TriCore::CMPF_ddd : TriCore::CMPDF_dee;
  Register CmpReg = MRI.createVirtualRegister(&TriCore::DataRegsRegClass);
  auto FCmpInstr = MIRBuilder.buildInstr(Opcode)
                       .addDef(CmpReg)
                       .addUse(I.getOperand(2).getReg())
                       .addUse(I.getOperand(3).getReg());

  // Get the opcode and the bits to look at
  FCmpConstants CmpCnsts = getFCmpConstants(Pred);
  auto ResInstr = MIRBuilder.buildInstr(CmpCnsts.SelectResultOpcode)
                      .addDef(DstReg)
                      .addUse(CmpReg)
                      .addImm(CmpCnsts.FirstBitOffset)
                      .addUse(CmpReg)
                      .addImm(CmpCnsts.SecondBitOffset);

  constrainSelectedInstRegOperands(*ResInstr, TII, TRI, RBI);
  constrainSelectedInstRegOperands(*FCmpInstr, TII, TRI, RBI);

  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectICmp(
    MachineInstr &I, const MachineRegisterInfo &MRI) const {
  assert(I.getOpcode() == TargetOpcode::G_ICMP && "Expected G_ICMP!");

  // Check for the correct type
  const LLT &Ty = MRI.getType(I.getOperand(0).getReg());
  if (Ty != LLT::scalar(32)) {
    LLVM_DEBUG(dbgs() << "G_ICMP has type: " << Ty << ", expected "
                      << LLT::scalar(32) << "\n");
    return false;
  }

  // G_ICMP has 4 operands, in order: result, predicate, lhs, rhs
  assert(I.getNumOperands() == 4 && "Expected G_ICMP to have 4 operands.");

  // Get the corresponding CmpOpCode for the Predicate and operand type and
  // check if the operands need to be flipped.
  MachineOperand &Predicate = I.getOperand(1);
  auto P = (CmpInst::Predicate)Predicate.getPredicate();

  assert(I.getOperand(2).isReg() && I.getOperand(3).isReg() &&
         "Expected LHS and RHS to be registers!");

  const Register &SrcReg = I.getOperand(2).getReg();
  const RegisterBank *RB = RBI.getRegBank(SrcReg, MRI, TRI);

  if (!RB) {
    LLVM_DEBUG(
        dbgs() << "Could not determine register bank for source register.\n");
    return false;
  }

  // Check if we can fold any of the operands into the compare instruction
  if (tryFoldIntegerCompare(I)) {
    I.removeFromParent();
    return true;
  }

  bool SwapOperands = false;
  unsigned CmpOpCode = getCmpOpCodeForPredicate(P, *RB, SwapOperands);

  if (CmpOpCode == 0) {
    LLVM_DEBUG(dbgs() << "Cannot select G_ICMP for predicate " << Predicate
                      << " and RegBank " << *RB << ".\n");
    return false;
  }

  unsigned LHSIdx = SwapOperands ? 3 : 2;
  unsigned RHSIdx = SwapOperands ? 2 : 3;

  const Register &LHS = I.getOperand(LHSIdx).getReg();
  const Register &RHS = I.getOperand(RHSIdx).getReg();

  // Build compare instruction
  MachineIRBuilder MIRBuilder(I);

  auto CmpMI = MIRBuilder.buildInstr(CmpOpCode)
                   .addDef(I.getOperand(0).getReg())
                   .addUse(LHS)
                   .addUse(RHS);

  constrainSelectedInstRegOperands(*CmpMI, TII, TRI, RBI);

  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectIntrinsicWithSideEffects(
    MachineInstr &I, MachineRegisterInfo &MRI) const {
  assert(I.getOpcode() == TargetOpcode::G_INTRINSIC_W_SIDE_EFFECTS);

  // Find the intrinsic ID.
  unsigned IntrinID = findIntrinsicID(I);
  if (!IntrinID) {
    LLVM_DEBUG(dbgs() << "Could not find intrinsic ID!\n");
    return false;
  }

  // Select the instruction.
  switch (IntrinID) {
  default:
    LLVM_DEBUG(dbgs() << "Unsupported intrinsic: " << IntrinID << ".\n");
    return false;
  case Intrinsic::flt_rounds:
    return selectFltRounds(I, MRI);
  }
}

bool TriCoreInstructionSelector::selectMerge(MachineInstr &I,
                                             MachineRegisterInfo &MRI) const {
  assert(I.getOpcode() == TargetOpcode::G_MERGE_VALUES);

  // G_MERGE_VALUES can be selected using subregister inserts and the insert
  // instruction
  const unsigned NumSrcOperands = I.getNumOperands() - 1;
  const Register SrcReg = I.getOperand(1).getReg();
  const Register DstReg = I.getOperand(0).getReg();

  const LLT SrcTy = MRI.getType(SrcReg);
  const LLT DstTy = MRI.getType(DstReg);

  const unsigned SrcSize = SrcTy.getSizeInBits();
  const unsigned DstSize = DstTy.getSizeInBits();

  // Types must be a power-of-2 between s8 and s64.
  if (!isPowerOf2_32(SrcSize) || !isPowerOf2_32(DstSize) || DstSize > 64 ||
      SrcSize < 8) {
    LLVM_DEBUG(dbgs() << "G_MERGE_VALUES is only supported for power-of-2 "
                         "types between 8 and 64-bit. Source size: "
                      << SrcSize << "-bit, destination size: " << DstSize
                      << "-bit\n");
    return false;
  }

  const RegisterBank *SrcRB = RBI.getRegBank(SrcReg, MRI, TRI);
  const RegisterBank *DstRB = RBI.getRegBank(DstReg, MRI, TRI);

  // Check register banks. Merges which cannot use subreg inserts must be on
  // the DataRegBank
  if (!SrcRB || !DstRB ||
      (SrcSize < 32 && (SrcRB->getID() != TriCore::DataRegBankID ||
                        DstRB->getID() != TriCore::DataRegBankID))) {
    LLVM_DEBUG(
        dbgs() << "Failed to determine register bank for G_MERGE_VALUES\n");
    return false;
  }

  MachineIRBuilder MIRBuilder(I);

  // Build 32-bit merge if the result fits in 32-bits
  if (DstSize <= 32) {
    assert(SrcRB->getID() == TriCore::DataRegBankID &&
           DstRB->getID() == TriCore::DataRegBankID &&
           "Unexpected register bank for G_MERGE_VALUES");

    // Gather the source registers
    SmallVector<Register, 4> SrcRegs;
    for (unsigned i = 1; i < NumSrcOperands + 1; ++i)
      SrcRegs.push_back(I.getOperand(i).getReg());

    // Build a 32-bit merge
    emit32BitMerge(SrcRegs, DstReg, MIRBuilder, MRI);

  } else {
    // 64-bit merge requires 2 32-bit merges (if needed) and two subreg inserts
    assert(DstSize == 64 && "Unexpected size for G_MERGE_VALUES");

    // Source registers for the subreg inserts. Also destination regs for the
    // 32-bit merges
    const Register LowerDstReg =
        SrcSize == 32 ? I.getOperand(1).getReg()
                      : MRI.createVirtualRegister(&TriCore::DataRegsRegClass);
    const Register UpperDstReg =
        SrcSize == 32 ? I.getOperand(2).getReg()
                      : MRI.createVirtualRegister(&TriCore::DataRegsRegClass);

    // Check if we need to build 32-bit merges first
    if (SrcSize < 32) {
      // Gather source registers
      SmallVector<Register, 4> LowerSrcRegs;
      SmallVector<Register, 4> UpperSrcRegs;

      for (unsigned i = 0, j = NumSrcOperands / 2; i < NumSrcOperands / 2;
           ++i, ++j) {
        LowerSrcRegs.push_back(I.getOperand(i + 1).getReg());
        UpperSrcRegs.push_back(I.getOperand(j + 1).getReg());
      }

      // Build 32-bit merges
      emit32BitMerge(LowerSrcRegs, LowerDstReg, MIRBuilder, MRI);
      emit32BitMerge(UpperSrcRegs, UpperDstReg, MIRBuilder, MRI);
    }

    // Build a register sequence to complete the merge
    MIRBuilder.buildInstr(TargetOpcode::REG_SEQUENCE)
        .addDef(DstReg)
        .addUse(LowerDstReg)
        .addImm(TriCore::dsub0)
        .addUse(UpperDstReg)
        .addImm(TriCore::dsub1);

    // We need to manually constrain the destination register. Source registers
    // are already constrained through the 32-bit merges
    TriCoreRegisterBankInfo::constrainGenericRegister(
        DstReg, TriCore::ExtDataRegsRegClass, MRI);
  }

  // Finished with merge selection
  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectLoadStore(
    MachineInstr &I, const MachineRegisterInfo &MRI) const {

  const Register &ValReg = I.getOperand(0).getReg();
  Register PtrReg = I.getOperand(1).getReg();
  const RegisterBank &DstRB = *RBI.getRegBank(ValReg, MRI, TRI);

  auto &MemOp = **I.memoperands_begin();

  const bool IsStore = I.getOpcode() == TargetOpcode::G_STORE;

  bool InsertBarrierBefore = false;
  bool InsertBarrierAfter = false;

  if (MemOp.isAtomic()) {
    // TODO: support other atomic memory operations if needed
    switch (MemOp.getOrdering()) {
    default:
      LLVM_DEBUG(dbgs() << "Atomic load/store not fully supported yet\n");
      return false;
    case AtomicOrdering::Acquire:
      // For acquire it is enough to have a memory synchronization barrier after
      // the actual load instruction. See the LLVM LangRef manual about
      // acquire semantics
      LLVM_DEBUG(
          dbgs()
          << "Load-acquire found. Inserting DSYNC after memory operation\n");
      InsertBarrierAfter = true;
      break;
    case AtomicOrdering::Release:
      // Release is mostly similar to acquire, but requires the synchronization
      // to happen before the memory access
      LLVM_DEBUG(
          dbgs()
          << "Store-release found. Inserting DSYNC before memory operation\n");
      InsertBarrierBefore = true;
      break;
    }
  }

  const unsigned MemSizeInBits = MemOp.getSize() * 8;

#ifndef NDEBUG
  // Sanity check that we have a pointer as address
  const RegisterBank &PtrRB = *RBI.getRegBank(PtrReg, MRI, TRI);
  assert(PtrRB.getID() == TriCore::AddrRegBankID &&
         "Load/Store pointer operand is not on AddrRegBank");
  assert(MRI.getType(PtrReg).isPointer() &&
         "Load/Store pointer operand is not a pointer");
#endif

  const unsigned NewOpc =
      getLoadStoreOpCode(I.getOpcode(), DstRB.getID(), MemSizeInBits);

  // If we couldn't find a matching opcode for the combination of regbank and
  // access size, bail out
  if (NewOpc == I.getOpcode()) {
    LLVM_DEBUG(dbgs() << "No load/store operation available for the given "
                         "combination of regbank and memory size. RB: "
                      << DstRB << ", MemSize: " << MemSizeInBits << "\n");
    return false;
  }

  MachineIRBuilder MIRBuilder(I);

  // Insert a DSYNC barrier before the memory operation if needed
  if (InsertBarrierBefore)
    MIRBuilder.buildInstr(TriCore::DSYNC);

  // Build load/store
  auto MemMI = MIRBuilder.buildInstr(NewOpc);

  if (!IsStore)
    MemMI = MemMI.addDef(ValReg);

  uint64_t Offset = 0;
  auto *PtrMI = MRI.getVRegDef(PtrReg);
  if (PtrMI->getOpcode() == TargetOpcode::G_PTR_ADD) {
    if (auto COff = getConstantVRegVal(PtrMI->getOperand(2).getReg(), MRI)) {
      if (TII.doesOffsetFitInOffsetOperand(NewOpc, *COff)) {
        PtrReg = PtrMI->getOperand(1).getReg();
        Offset = *COff;
      }
    }
  }

  MemMI = MemMI.addUse(PtrReg).addImm(Offset);
  if (IsStore)
    MemMI = MemMI.addUse(ValReg);

  MemMI = MemMI.addMemOperand(&MemOp);
  constrainSelectedInstRegOperands(*MemMI, TII, TRI, RBI);

  // Insert a DSYNC barrier after the memory operation if needed
  if (InsertBarrierAfter)
    MIRBuilder.buildInstr(TriCore::DSYNC);

  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectPtrAdd(
    MachineInstr &I, const MachineRegisterInfo &MRI) const {
  const Register &DstReg = I.getOperand(0).getReg();
  const Register &Src1Reg = I.getOperand(1).getReg();
  const Register &Src2Reg = I.getOperand(2).getReg();

  const LLT &PtrTy = MRI.getType(DstReg);
  const LLT &ScalarTy = MRI.getType(Src2Reg);

  // Check for correct types
  if (!checkType(LLT::pointer(0, 32), PtrTy, "G_PTR_ADD") ||
      !checkType(LLT::scalar(32), ScalarTy, "G_PTR_ADD"))
    return false;

  // Emit an add depending on which register bank we're on
  const RegisterBank &DstRB = *RBI.getRegBank(DstReg, MRI, TRI);
  const RegisterBank &Src1RB = *RBI.getRegBank(Src1Reg, MRI, TRI);
  const RegisterBank &Src2RB = *RBI.getRegBank(Src2Reg, MRI, TRI);

  // Make sure that this G_PTR_ADD happens on the same register bank
  if (DstRB.getID() != Src1RB.getID() || DstRB.getID() != Src2RB.getID()) {
    LLVM_DEBUG(dbgs() << "Unexpected regbank for G_PTR_ADD. DstRB: " << DstRB
                      << ", Src1RB: " << Src1RB << ", Src2RB: " << Src2RB
                      << '\n');
    return false;
  }

  const unsigned AddOpc = DstRB.getID() == TriCore::AddrRegBankID
                              ? TriCore::ADDA_aaa
                              : TriCore::ADD_ddd;

  I.setDesc(TII.get(AddOpc));
  constrainSelectedInstRegOperands(I, TII, TRI, RBI);
  return true;
}

bool TriCoreInstructionSelector::selectSelect(
    MachineInstr &I, const MachineRegisterInfo &MRI) const {
  const LLT DstTy = MRI.getType(I.getOperand(0).getReg());
  const LLT Src1Ty = MRI.getType(I.getOperand(2).getReg());

  // G_SELECT of scalars is already handled in TableGen
  if (!checkType(LLT::pointer(0, 32), DstTy, "G_SELECT") ||
      !checkType(LLT::pointer(0, 32), Src1Ty, "G_SELECT"))
    return false;

  // Our TriCore instruction uses the exact same operand order, so we only need
  // to change the opcode
  I.setDesc(TII.get(TriCore::SEL_dddd));
  return constrainSelectedInstRegOperands(I, TII, TRI, RBI);
}

bool TriCoreInstructionSelector::selectTrunc(MachineInstr &I,
                                             MachineRegisterInfo &MRI) const {
  const LLT DstTy = MRI.getType(I.getOperand(0).getReg());
  const LLT SrcTy = MRI.getType(I.getOperand(1).getReg());

  // Make sure that TableGen handled our supported case
  if (DstTy == LLT::scalar(32) && SrcTy == LLT::scalar(64))
    llvm_unreachable("G_TRUNC from 64 to 32 bits can be handled by TableGen");

  const Register DstReg = I.getOperand(0).getReg();
  const Register SrcReg = I.getOperand(1).getReg();

  const RegisterBank &DstRB = *RBI.getRegBank(DstReg, MRI, TRI);
  const RegisterBank &SrcRB = *RBI.getRegBank(SrcReg, MRI, TRI);

  const TargetRegisterClass *DstRC = getRegClassForTypeOnBank(DstTy, DstRB);
  const TargetRegisterClass *SrcRC = getRegClassForTypeOnBank(SrcTy, SrcRB);

  if (!DstRC || !SrcRC) {
    LLVM_DEBUG(
        dbgs() << "Unable to determine TargetRegisterClass for G_TRUNC\n");
    return false;
  }

  // Try to constrain the registers to their classes
  if (!TriCoreRegisterBankInfo::constrainGenericRegister(DstReg, *DstRC, MRI) ||
      !TriCoreRegisterBankInfo::constrainGenericRegister(SrcReg, *SrcRC, MRI)) {
    LLVM_DEBUG(dbgs() << "Failed to constrain G_TRUNC\n");
    return false;
  }

  // Change G_TRUNC to COPY, possibly using a subregister
  if (DstRC == SrcRC) {
    // Nothing to do
  } else if ((DstRC == &TriCore::DataRegsRegClass &&
              SrcRC == &TriCore::ExtDataRegsRegClass) ||
             (DstRC == &TriCore::AddrRegsRegClass &&
              SrcRC == &TriCore::ExtAddrRegsRegClass)) {
    // Use subregister copy
    const unsigned SubRegIdx = DstRB.getID() == TriCore::DataRegBankID
                                   ? TriCore::dsub0
                                   : TriCore::asub0;
    I.getOperand(1).setSubReg(SubRegIdx);
  } else {
    LLVM_DEBUG(dbgs() << "Unhandled mismatched register classes in G_TRUNC\n");
    return false;
  }

  I.setDesc(TII.get(TargetOpcode::COPY));
  return true;
}

bool TriCoreInstructionSelector::selectUnmerge(MachineInstr &I,
                                               MachineRegisterInfo &MRI) const {
  assert(I.getOpcode() == TargetOpcode::G_UNMERGE_VALUES);

  // G_UNMERGE_VALUES can be selected using subregister copies and the
  // extract instruction
  const unsigned NumDstOperands = I.getNumOperands() - 1;
  const Register SrcReg = I.getOperand(NumDstOperands).getReg();
  const Register DstReg = I.getOperand(0).getReg();

  const LLT SrcTy = MRI.getType(SrcReg);
  const LLT DstTy = MRI.getType(DstReg);

  const unsigned SrcSize = SrcTy.getSizeInBits();
  const unsigned DstSize = DstTy.getSizeInBits();

  // Types must be a power-of-2 between s8 and s64.
  if (!isPowerOf2_32(SrcSize) || !isPowerOf2_32(DstSize) || SrcSize > 64 ||
      DstSize < 8) {
    LLVM_DEBUG(dbgs() << "G_UNMERGE_VALUES is only supported for power-of-2 "
                         "types between 8 and 64-bit. Source size: "
                      << SrcSize << "-bit, destination size: " << DstSize
                      << "-bit\n");
    return false;
  }

  const RegisterBank *SrcRB = RBI.getRegBank(SrcReg, MRI, TRI);
  const RegisterBank *DstRB = RBI.getRegBank(DstReg, MRI, TRI);

  // Check register banks. Unmerges which cannot use subreg copies must be on
  // the DataRegBank
  if (!SrcRB || !DstRB ||
      (DstSize < 32 && (SrcRB->getID() != TriCore::DataRegBankID ||
                        DstRB->getID() != TriCore::DataRegBankID))) {
    LLVM_DEBUG(
        dbgs() << "Failed to determine register bank for G_UNMERGE_VALUES\n");
    return false;
  }

  MachineIRBuilder MIRBuilder(I);

  if (SrcSize <= 32) {
    assert(SrcRB->getID() == TriCore::DataRegBankID &&
           DstRB->getID() == TriCore::DataRegBankID &&
           "Unexpected register bank for G_UNMERGE_VALUES");

    // Gather destination registers
    SmallVector<Register, 4> DstRegs;
    for (unsigned i = 0; i < NumDstOperands; ++i)
      DstRegs.push_back(I.getOperand(i).getReg());

    // Build 32-bit unmerge
    emit32BitUnmerge(SrcReg, DstRegs, MIRBuilder, MRI);

  } else {
    // When unmerging a 64-bit value we unmerge to 32-bit first using subreg
    // copies and then use 2 32-bit unmerges if needed
    assert(SrcSize == 64 && DstSize <= 32 &&
           "Unexpected size for G_UNMERGE_VALUES");

    // Get register class for the destination registers
    const TargetRegisterClass *DstRC = getRegClassForRegBank(*DstRB, DstSize);

    if (!DstRC) {
      LLVM_DEBUG(dbgs() << "Cannot determine destination register class for "
                           "G_UNMERGE_VALUES. Destination size: "
                        << DstSize << "-bit\n");
      return false;
    }

    // Registers for the 64-to-32-bit unmerge. Use actual destination
    // registers if that is the actual destination size
    const Register LowerReg = DstSize == 32 ? I.getOperand(0).getReg()
                                            : MRI.createVirtualRegister(DstRC);
    const Register UpperReg = DstSize == 32 ? I.getOperand(1).getReg()
                                            : MRI.createVirtualRegister(DstRC);

    // Build subregister copies
    MIRBuilder.buildInstr(TargetOpcode::COPY)
        .addDef(LowerReg)
        .addUse(SrcReg, 0, TriCore::dsub0);

    MIRBuilder.buildInstr(TargetOpcode::COPY)
        .addDef(UpperReg)
        .addUse(SrcReg, 0, TriCore::dsub1);

    // Constrain destination registers of the copies. No need to constrain the
    // source register as it will be constrained once we hit one of its defs.
    if (!TriCoreRegisterBankInfo::constrainGenericRegister(LowerReg, *DstRC,
                                                           MRI) ||
        !TriCoreRegisterBankInfo::constrainGenericRegister(UpperReg, *DstRC,
                                                           MRI)) {
      LLVM_DEBUG(
          dbgs() << "Failed to constrain registers for G_UNMERGE_VALUES\n");
      return false;
    }

    // Emit 32-bit unmerge if needed
    if (DstSize < 32) {
      // Gather destination registers for lower and upper unmerge
      SmallVector<Register, 4> LowerDstRegs;
      SmallVector<Register, 4> UpperDstRegs;

      assert(NumDstOperands % 2 == 0 &&
             "Unexpected number of operands for G_UNMERGE_VALUES");

      for (unsigned i = 0, j = NumDstOperands / 2; i < NumDstOperands / 2;
           ++i, ++j) {
        LowerDstRegs.push_back(I.getOperand(i).getReg());
        UpperDstRegs.push_back(I.getOperand(j).getReg());
      }

      // Emit 2 32-bit unmerges to get to the actual destination registers
      emit32BitUnmerge(LowerReg, LowerDstRegs, MIRBuilder, MRI);
      emit32BitUnmerge(UpperReg, UpperDstRegs, MIRBuilder, MRI);
    }
  }

  // Finish selection
  I.removeFromParent();
  return true;
}

bool TriCoreInstructionSelector::selectVaStart(MachineInstr &I,
                                               MachineFunction &MF,
                                               MachineRegisterInfo &MRI) const {
  TriCoreFunctionInfo *FuncInfo = MF.getInfo<TriCoreFunctionInfo>();
  Register ListReg = I.getOperand(0).getReg();

  // Check for correct type
  if (!checkType(LLT::pointer(0, 32), MRI.getType(ListReg), "G_VASTART"))
    return false;

  Register ArgsAddrReg = MRI.createVirtualRegister(&TriCore::AddrRegsRegClass);
  int FI = FuncInfo->getVarArgsFrameIndex();
  MachineIRBuilder MIRBuilder(I);

  // storing the address of the first vararg to ArgsAddrReg
  auto MIB = MIRBuilder.buildInstr(TriCore::LEA_aac)
                 .addDef(ArgsAddrReg)
                 .addFrameIndex(FI)
                 .addImm(0);

  if (!constrainSelectedInstRegOperands(*MIB, TII, TRI, RBI)) {
    LLVM_DEBUG(
        dbgs() << "Failed to constrain LEA's registers for G_VASTART.\n");
    return false;
  }

  // storing the address of the first vararg to the local va_list variable
  MIB = MIRBuilder.buildInstr(TriCore::STA_alca)
            .addUse(ListReg)
            .addImm(0)
            .addUse(ArgsAddrReg);

  if (!constrainSelectedInstRegOperands(*MIB, TII, TRI, RBI)) {
    LLVM_DEBUG(
        dbgs() << "Failed to constrain ST.A's registers for G_VASTART.\n");
    return false;
  }

  I.eraseFromParent();
  return true;
}

void TriCoreInstructionSelector::renderNegImm(MachineInstrBuilder &MIB,
                                              const MachineInstr &MI,
                                              int OpIdx) const {
  const MachineRegisterInfo &MRI = MI.getParent()->getParent()->getRegInfo();
  assert(MI.getOpcode() == TargetOpcode::G_CONSTANT && OpIdx == -1 &&
         "Expected G_CONSTANT");
  Optional<int64_t> CstVal = getConstantVRegVal(MI.getOperand(0).getReg(), MRI);
  assert(CstVal && "Expected constant value");
  MIB.addImm(-CstVal.getValue());
}

namespace llvm {
InstructionSelector *
createTriCoreInstructionSelector(const TriCoreTargetMachine &TM,
                                 TriCoreSubtarget &Subtarget,
                                 TriCoreRegisterBankInfo &RBI) {
  return new TriCoreInstructionSelector(TM, Subtarget, RBI);
}
} // end namespace llvm
